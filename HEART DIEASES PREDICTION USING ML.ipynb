{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4235</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>84.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4236</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>87.0</td>\n",
       "      <td>19.16</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4237</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>133.5</td>\n",
       "      <td>83.0</td>\n",
       "      <td>21.47</td>\n",
       "      <td>80.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4238</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>25.60</td>\n",
       "      <td>67.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4239</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>20.91</td>\n",
       "      <td>85.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4240 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      male  age  education  currentSmoker  cigsPerDay  BPMeds  \\\n",
       "0        1   39        4.0              0         0.0     0.0   \n",
       "1        0   46        2.0              0         0.0     0.0   \n",
       "2        1   48        1.0              1        20.0     0.0   \n",
       "3        0   61        3.0              1        30.0     0.0   \n",
       "4        0   46        3.0              1        23.0     0.0   \n",
       "...    ...  ...        ...            ...         ...     ...   \n",
       "4235     0   48        2.0              1        20.0     NaN   \n",
       "4236     0   44        1.0              1        15.0     0.0   \n",
       "4237     0   52        2.0              0         0.0     0.0   \n",
       "4238     1   40        3.0              0         0.0     0.0   \n",
       "4239     0   39        3.0              1        30.0     0.0   \n",
       "\n",
       "      prevalentStroke  prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  \\\n",
       "0                   0             0         0    195.0  106.0   70.0  26.97   \n",
       "1                   0             0         0    250.0  121.0   81.0  28.73   \n",
       "2                   0             0         0    245.0  127.5   80.0  25.34   \n",
       "3                   0             1         0    225.0  150.0   95.0  28.58   \n",
       "4                   0             0         0    285.0  130.0   84.0  23.10   \n",
       "...               ...           ...       ...      ...    ...    ...    ...   \n",
       "4235                0             0         0    248.0  131.0   72.0  22.00   \n",
       "4236                0             0         0    210.0  126.5   87.0  19.16   \n",
       "4237                0             0         0    269.0  133.5   83.0  21.47   \n",
       "4238                0             1         0    185.0  141.0   98.0  25.60   \n",
       "4239                0             0         0    196.0  133.0   86.0  20.91   \n",
       "\n",
       "      heartRate  glucose  TenYearCHD  \n",
       "0          80.0     77.0           0  \n",
       "1          95.0     76.0           0  \n",
       "2          75.0     70.0           0  \n",
       "3          65.0    103.0           1  \n",
       "4          85.0     85.0           0  \n",
       "...         ...      ...         ...  \n",
       "4235       84.0     86.0           0  \n",
       "4236       86.0      NaN           0  \n",
       "4237       80.0    107.0           0  \n",
       "4238       67.0     72.0           0  \n",
       "4239       85.0     80.0           0  \n",
       "\n",
       "[4240 rows x 16 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the dataset into jupyter notebook\n",
    "import pandas as pd\n",
    "df=pd.read_csv(\"D:/DATA SCIENCE NOTE/framingham.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4240, 16)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0     1   39        4.0              0         0.0     0.0                0   \n",
       "1     0   46        2.0              0         0.0     0.0                0   \n",
       "2     1   48        1.0              1        20.0     0.0                0   \n",
       "3     0   61        3.0              1        30.0     0.0                0   \n",
       "4     0   46        3.0              1        23.0     0.0                0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "1             0         0    250.0  121.0   81.0  28.73       95.0     76.0   \n",
       "2             0         0    245.0  127.5   80.0  25.34       75.0     70.0   \n",
       "3             1         0    225.0  150.0   95.0  28.58       65.0    103.0   \n",
       "4             0         0    285.0  130.0   84.0  23.10       85.0     85.0   \n",
       "\n",
       "   TenYearCHD  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4235</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>84.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4236</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>87.0</td>\n",
       "      <td>19.16</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4237</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>133.5</td>\n",
       "      <td>83.0</td>\n",
       "      <td>21.47</td>\n",
       "      <td>80.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4238</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>25.60</td>\n",
       "      <td>67.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4239</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>20.91</td>\n",
       "      <td>85.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4240 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      male  age  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0        1   39              0         0.0     0.0                0   \n",
       "1        0   46              0         0.0     0.0                0   \n",
       "2        1   48              1        20.0     0.0                0   \n",
       "3        0   61              1        30.0     0.0                0   \n",
       "4        0   46              1        23.0     0.0                0   \n",
       "...    ...  ...            ...         ...     ...              ...   \n",
       "4235     0   48              1        20.0     NaN                0   \n",
       "4236     0   44              1        15.0     0.0                0   \n",
       "4237     0   52              0         0.0     0.0                0   \n",
       "4238     1   40              0         0.0     0.0                0   \n",
       "4239     0   39              1        30.0     0.0                0   \n",
       "\n",
       "      prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  \\\n",
       "0                0         0    195.0  106.0   70.0  26.97       80.0   \n",
       "1                0         0    250.0  121.0   81.0  28.73       95.0   \n",
       "2                0         0    245.0  127.5   80.0  25.34       75.0   \n",
       "3                1         0    225.0  150.0   95.0  28.58       65.0   \n",
       "4                0         0    285.0  130.0   84.0  23.10       85.0   \n",
       "...            ...       ...      ...    ...    ...    ...        ...   \n",
       "4235             0         0    248.0  131.0   72.0  22.00       84.0   \n",
       "4236             0         0    210.0  126.5   87.0  19.16       86.0   \n",
       "4237             0         0    269.0  133.5   83.0  21.47       80.0   \n",
       "4238             1         0    185.0  141.0   98.0  25.60       67.0   \n",
       "4239             0         0    196.0  133.0   86.0  20.91       85.0   \n",
       "\n",
       "      glucose  TenYearCHD  \n",
       "0        77.0           0  \n",
       "1        76.0           0  \n",
       "2        70.0           0  \n",
       "3       103.0           1  \n",
       "4        85.0           0  \n",
       "...       ...         ...  \n",
       "4235     86.0           0  \n",
       "4236      NaN           0  \n",
       "4237    107.0           0  \n",
       "4238     72.0           0  \n",
       "4239     80.0           0  \n",
       "\n",
       "[4240 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#education column has no relation with \"TenYearCHD\" so remove education columns\n",
    "df1=df.drop(columns=[\"education\"])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male  age  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0     1   39              0         0.0     0.0                0   \n",
       "1     0   46              0         0.0     0.0                0   \n",
       "2     1   48              1        20.0     0.0                0   \n",
       "3     0   61              1        30.0     0.0                0   \n",
       "4     0   46              1        23.0     0.0                0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "1             0         0    250.0  121.0   81.0  28.73       95.0     76.0   \n",
       "2             0         0    245.0  127.5   80.0  25.34       75.0     70.0   \n",
       "3             1         0    225.0  150.0   95.0  28.58       65.0    103.0   \n",
       "4             0         0    285.0  130.0   84.0  23.10       85.0     85.0   \n",
       "\n",
       "   TenYearCHD  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>male</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.029014</td>\n",
       "      <td>0.197026</td>\n",
       "      <td>0.317143</td>\n",
       "      <td>-0.052504</td>\n",
       "      <td>-0.004550</td>\n",
       "      <td>0.005853</td>\n",
       "      <td>0.015693</td>\n",
       "      <td>-0.070413</td>\n",
       "      <td>-0.035879</td>\n",
       "      <td>0.058199</td>\n",
       "      <td>0.081871</td>\n",
       "      <td>-0.116932</td>\n",
       "      <td>0.005979</td>\n",
       "      <td>0.088374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>age</td>\n",
       "      <td>-0.029014</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.213662</td>\n",
       "      <td>-0.192959</td>\n",
       "      <td>0.123052</td>\n",
       "      <td>0.057679</td>\n",
       "      <td>0.306799</td>\n",
       "      <td>0.101314</td>\n",
       "      <td>0.262554</td>\n",
       "      <td>0.394053</td>\n",
       "      <td>0.205586</td>\n",
       "      <td>0.136096</td>\n",
       "      <td>-0.012843</td>\n",
       "      <td>0.122356</td>\n",
       "      <td>0.225408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>currentSmoker</td>\n",
       "      <td>0.197026</td>\n",
       "      <td>-0.213662</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.769774</td>\n",
       "      <td>-0.048927</td>\n",
       "      <td>-0.032980</td>\n",
       "      <td>-0.103710</td>\n",
       "      <td>-0.044285</td>\n",
       "      <td>-0.046488</td>\n",
       "      <td>-0.130281</td>\n",
       "      <td>-0.107933</td>\n",
       "      <td>-0.167857</td>\n",
       "      <td>0.062686</td>\n",
       "      <td>-0.056726</td>\n",
       "      <td>0.019448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cigsPerDay</td>\n",
       "      <td>0.317143</td>\n",
       "      <td>-0.192959</td>\n",
       "      <td>0.769774</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.046155</td>\n",
       "      <td>-0.032711</td>\n",
       "      <td>-0.066645</td>\n",
       "      <td>-0.037089</td>\n",
       "      <td>-0.026479</td>\n",
       "      <td>-0.088797</td>\n",
       "      <td>-0.056715</td>\n",
       "      <td>-0.093293</td>\n",
       "      <td>0.075564</td>\n",
       "      <td>-0.058886</td>\n",
       "      <td>0.057755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BPMeds</td>\n",
       "      <td>-0.052504</td>\n",
       "      <td>0.123052</td>\n",
       "      <td>-0.048927</td>\n",
       "      <td>-0.046155</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.117370</td>\n",
       "      <td>0.261067</td>\n",
       "      <td>0.052060</td>\n",
       "      <td>0.080623</td>\n",
       "      <td>0.254194</td>\n",
       "      <td>0.194122</td>\n",
       "      <td>0.100702</td>\n",
       "      <td>0.015230</td>\n",
       "      <td>0.051197</td>\n",
       "      <td>0.087519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>prevalentStroke</td>\n",
       "      <td>-0.004550</td>\n",
       "      <td>0.057679</td>\n",
       "      <td>-0.032980</td>\n",
       "      <td>-0.032711</td>\n",
       "      <td>0.117370</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.074791</td>\n",
       "      <td>0.006955</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>0.045153</td>\n",
       "      <td>0.025909</td>\n",
       "      <td>-0.017674</td>\n",
       "      <td>0.018440</td>\n",
       "      <td>0.061823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>prevalentHyp</td>\n",
       "      <td>0.005853</td>\n",
       "      <td>0.306799</td>\n",
       "      <td>-0.103710</td>\n",
       "      <td>-0.066645</td>\n",
       "      <td>0.261067</td>\n",
       "      <td>0.074791</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.077752</td>\n",
       "      <td>0.163632</td>\n",
       "      <td>0.696656</td>\n",
       "      <td>0.615840</td>\n",
       "      <td>0.301344</td>\n",
       "      <td>0.146815</td>\n",
       "      <td>0.086656</td>\n",
       "      <td>0.177458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>diabetes</td>\n",
       "      <td>0.015693</td>\n",
       "      <td>0.101314</td>\n",
       "      <td>-0.044285</td>\n",
       "      <td>-0.037089</td>\n",
       "      <td>0.052060</td>\n",
       "      <td>0.006955</td>\n",
       "      <td>0.077752</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.040348</td>\n",
       "      <td>0.111265</td>\n",
       "      <td>0.050260</td>\n",
       "      <td>0.087068</td>\n",
       "      <td>0.048986</td>\n",
       "      <td>0.617630</td>\n",
       "      <td>0.097344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>totChol</td>\n",
       "      <td>-0.070413</td>\n",
       "      <td>0.262554</td>\n",
       "      <td>-0.046488</td>\n",
       "      <td>-0.026479</td>\n",
       "      <td>0.080623</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.163632</td>\n",
       "      <td>0.040348</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.208734</td>\n",
       "      <td>0.164698</td>\n",
       "      <td>0.115992</td>\n",
       "      <td>0.091127</td>\n",
       "      <td>0.046538</td>\n",
       "      <td>0.082369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sysBP</td>\n",
       "      <td>-0.035879</td>\n",
       "      <td>0.394053</td>\n",
       "      <td>-0.130281</td>\n",
       "      <td>-0.088797</td>\n",
       "      <td>0.254194</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>0.696656</td>\n",
       "      <td>0.111265</td>\n",
       "      <td>0.208734</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.783952</td>\n",
       "      <td>0.326906</td>\n",
       "      <td>0.182155</td>\n",
       "      <td>0.140573</td>\n",
       "      <td>0.216374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>diaBP</td>\n",
       "      <td>0.058199</td>\n",
       "      <td>0.205586</td>\n",
       "      <td>-0.107933</td>\n",
       "      <td>-0.056715</td>\n",
       "      <td>0.194122</td>\n",
       "      <td>0.045153</td>\n",
       "      <td>0.615840</td>\n",
       "      <td>0.050260</td>\n",
       "      <td>0.164698</td>\n",
       "      <td>0.783952</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.377360</td>\n",
       "      <td>0.181021</td>\n",
       "      <td>0.061075</td>\n",
       "      <td>0.145112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BMI</td>\n",
       "      <td>0.081871</td>\n",
       "      <td>0.136096</td>\n",
       "      <td>-0.167857</td>\n",
       "      <td>-0.093293</td>\n",
       "      <td>0.100702</td>\n",
       "      <td>0.025909</td>\n",
       "      <td>0.301344</td>\n",
       "      <td>0.087068</td>\n",
       "      <td>0.115992</td>\n",
       "      <td>0.326906</td>\n",
       "      <td>0.377360</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.067451</td>\n",
       "      <td>0.087389</td>\n",
       "      <td>0.075300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>heartRate</td>\n",
       "      <td>-0.116932</td>\n",
       "      <td>-0.012843</td>\n",
       "      <td>0.062686</td>\n",
       "      <td>0.075564</td>\n",
       "      <td>0.015230</td>\n",
       "      <td>-0.017674</td>\n",
       "      <td>0.146815</td>\n",
       "      <td>0.048986</td>\n",
       "      <td>0.091127</td>\n",
       "      <td>0.182155</td>\n",
       "      <td>0.181021</td>\n",
       "      <td>0.067451</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.094546</td>\n",
       "      <td>0.022907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>glucose</td>\n",
       "      <td>0.005979</td>\n",
       "      <td>0.122356</td>\n",
       "      <td>-0.056726</td>\n",
       "      <td>-0.058886</td>\n",
       "      <td>0.051197</td>\n",
       "      <td>0.018440</td>\n",
       "      <td>0.086656</td>\n",
       "      <td>0.617630</td>\n",
       "      <td>0.046538</td>\n",
       "      <td>0.140573</td>\n",
       "      <td>0.061075</td>\n",
       "      <td>0.087389</td>\n",
       "      <td>0.094546</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.125590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TenYearCHD</td>\n",
       "      <td>0.088374</td>\n",
       "      <td>0.225408</td>\n",
       "      <td>0.019448</td>\n",
       "      <td>0.057755</td>\n",
       "      <td>0.087519</td>\n",
       "      <td>0.061823</td>\n",
       "      <td>0.177458</td>\n",
       "      <td>0.097344</td>\n",
       "      <td>0.082369</td>\n",
       "      <td>0.216374</td>\n",
       "      <td>0.145112</td>\n",
       "      <td>0.075300</td>\n",
       "      <td>0.022907</td>\n",
       "      <td>0.125590</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     male       age  currentSmoker  cigsPerDay    BPMeds  \\\n",
       "male             1.000000 -0.029014       0.197026    0.317143 -0.052504   \n",
       "age             -0.029014  1.000000      -0.213662   -0.192959  0.123052   \n",
       "currentSmoker    0.197026 -0.213662       1.000000    0.769774 -0.048927   \n",
       "cigsPerDay       0.317143 -0.192959       0.769774    1.000000 -0.046155   \n",
       "BPMeds          -0.052504  0.123052      -0.048927   -0.046155  1.000000   \n",
       "prevalentStroke -0.004550  0.057679      -0.032980   -0.032711  0.117370   \n",
       "prevalentHyp     0.005853  0.306799      -0.103710   -0.066645  0.261067   \n",
       "diabetes         0.015693  0.101314      -0.044285   -0.037089  0.052060   \n",
       "totChol         -0.070413  0.262554      -0.046488   -0.026479  0.080623   \n",
       "sysBP           -0.035879  0.394053      -0.130281   -0.088797  0.254194   \n",
       "diaBP            0.058199  0.205586      -0.107933   -0.056715  0.194122   \n",
       "BMI              0.081871  0.136096      -0.167857   -0.093293  0.100702   \n",
       "heartRate       -0.116932 -0.012843       0.062686    0.075564  0.015230   \n",
       "glucose          0.005979  0.122356      -0.056726   -0.058886  0.051197   \n",
       "TenYearCHD       0.088374  0.225408       0.019448    0.057755  0.087519   \n",
       "\n",
       "                 prevalentStroke  prevalentHyp  diabetes   totChol     sysBP  \\\n",
       "male                   -0.004550      0.005853  0.015693 -0.070413 -0.035879   \n",
       "age                     0.057679      0.306799  0.101314  0.262554  0.394053   \n",
       "currentSmoker          -0.032980     -0.103710 -0.044285 -0.046488 -0.130281   \n",
       "cigsPerDay             -0.032711     -0.066645 -0.037089 -0.026479 -0.088797   \n",
       "BPMeds                  0.117370      0.261067  0.052060  0.080623  0.254194   \n",
       "prevalentStroke         1.000000      0.074791  0.006955  0.000105  0.057000   \n",
       "prevalentHyp            0.074791      1.000000  0.077752  0.163632  0.696656   \n",
       "diabetes                0.006955      0.077752  1.000000  0.040348  0.111265   \n",
       "totChol                 0.000105      0.163632  0.040348  1.000000  0.208734   \n",
       "sysBP                   0.057000      0.696656  0.111265  0.208734  1.000000   \n",
       "diaBP                   0.045153      0.615840  0.050260  0.164698  0.783952   \n",
       "BMI                     0.025909      0.301344  0.087068  0.115992  0.326906   \n",
       "heartRate              -0.017674      0.146815  0.048986  0.091127  0.182155   \n",
       "glucose                 0.018440      0.086656  0.617630  0.046538  0.140573   \n",
       "TenYearCHD              0.061823      0.177458  0.097344  0.082369  0.216374   \n",
       "\n",
       "                    diaBP       BMI  heartRate   glucose  TenYearCHD  \n",
       "male             0.058199  0.081871  -0.116932  0.005979    0.088374  \n",
       "age              0.205586  0.136096  -0.012843  0.122356    0.225408  \n",
       "currentSmoker   -0.107933 -0.167857   0.062686 -0.056726    0.019448  \n",
       "cigsPerDay      -0.056715 -0.093293   0.075564 -0.058886    0.057755  \n",
       "BPMeds           0.194122  0.100702   0.015230  0.051197    0.087519  \n",
       "prevalentStroke  0.045153  0.025909  -0.017674  0.018440    0.061823  \n",
       "prevalentHyp     0.615840  0.301344   0.146815  0.086656    0.177458  \n",
       "diabetes         0.050260  0.087068   0.048986  0.617630    0.097344  \n",
       "totChol          0.164698  0.115992   0.091127  0.046538    0.082369  \n",
       "sysBP            0.783952  0.326906   0.182155  0.140573    0.216374  \n",
       "diaBP            1.000000  0.377360   0.181021  0.061075    0.145112  \n",
       "BMI              0.377360  1.000000   0.067451  0.087389    0.075300  \n",
       "heartRate        0.181021  0.067451   1.000000  0.094546    0.022907  \n",
       "glucose          0.061075  0.087389   0.094546  1.000000    0.125590  \n",
       "TenYearCHD       0.145112  0.075300   0.022907  0.125590    1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1b1eb194408>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#draw the heatmap to show the corelation graphics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(df1.corr(),annot=True,linewidth=1,linecolor=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male  age  cigsPerDay  BPMeds  prevalentStroke  prevalentHyp  diabetes  \\\n",
       "0     1   39         0.0     0.0                0             0         0   \n",
       "1     0   46         0.0     0.0                0             0         0   \n",
       "2     1   48        20.0     0.0                0             0         0   \n",
       "3     0   61        30.0     0.0                0             1         0   \n",
       "4     0   46        23.0     0.0                0             0         0   \n",
       "\n",
       "   totChol  sysBP    BMI  heartRate  glucose  TenYearCHD  \n",
       "0    195.0  106.0  26.97       80.0     77.0           0  \n",
       "1    250.0  121.0  28.73       95.0     76.0           0  \n",
       "2    245.0  127.5  25.34       75.0     70.0           0  \n",
       "3    225.0  150.0  28.58       65.0    103.0           1  \n",
       "4    285.0  130.0  23.10       85.0     85.0           0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CURRENT SMOKER AND CIGPER DAY HAVE HIGH CORELATION\n",
    "#SYSBP AND DIABP ALSO HAVE HIGH CORELATION\n",
    "#HENCE SELECT ONE FROM EACH PAIR\n",
    "df2=df1.drop(columns=[\"currentSmoker\",\"diaBP\"])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male  age  cigsPerDay  BPMeds  prevalentStroke  prevalentHyp  diabetes  \\\n",
       "0     1   39         0.0     0.0                0             0         0   \n",
       "1     0   46         0.0     0.0                0             0         0   \n",
       "2     1   48        20.0     0.0                0             0         0   \n",
       "3     0   61        30.0     0.0                0             1         0   \n",
       "4     0   46        23.0     0.0                0             0         0   \n",
       "\n",
       "   totChol  sysBP    BMI  heartRate  glucose  TenYearCHD  \n",
       "0    195.0  106.0  26.97       80.0     77.0           0  \n",
       "1    250.0  121.0  28.73       95.0     76.0           0  \n",
       "2    245.0  127.5  25.34       75.0     70.0           0  \n",
       "3    225.0  150.0  28.58       65.0    103.0           1  \n",
       "4    285.0  130.0  23.10       85.0     85.0           0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4240, 13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex  age  cigsPerDay  BPMeds  prevalentStroke  prevalentHyp  diabetes  \\\n",
       "0    1   39         0.0     0.0                0             0         0   \n",
       "1    0   46         0.0     0.0                0             0         0   \n",
       "2    1   48        20.0     0.0                0             0         0   \n",
       "3    0   61        30.0     0.0                0             1         0   \n",
       "4    0   46        23.0     0.0                0             0         0   \n",
       "\n",
       "   totChol  sysBP    BMI  heartRate  glucose  TenYearCHD  \n",
       "0    195.0  106.0  26.97       80.0     77.0           0  \n",
       "1    250.0  121.0  28.73       95.0     76.0           0  \n",
       "2    245.0  127.5  25.34       75.0     70.0           0  \n",
       "3    225.0  150.0  28.58       65.0    103.0           1  \n",
       "4    285.0  130.0  23.10       85.0     85.0           0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.rename(columns = {'male':'sex'},inplace=True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex  age  cigsPerDay  BPMeds  prevalentStroke  prevalentHyp  diabetes  \\\n",
       "0    1   39         0.0     0.0                0             0         0   \n",
       "1    0   46         0.0     0.0                0             0         0   \n",
       "2    1   48        20.0     0.0                0             0         0   \n",
       "3    0   61        30.0     0.0                0             1         0   \n",
       "4    0   46        23.0     0.0                0             0         0   \n",
       "\n",
       "   totChol  sysBP    BMI  heartRate  glucose  TenYearCHD  \n",
       "0    195.0  106.0  26.97       80.0     77.0           0  \n",
       "1    250.0  121.0  28.73       95.0     76.0           0  \n",
       "2    245.0  127.5  25.34       75.0     70.0           0  \n",
       "3    225.0  150.0  28.58       65.0    103.0           1  \n",
       "4    285.0  130.0  23.10       85.0     85.0           0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "70.0\n"
     ]
    }
   ],
   "source": [
    "print(df2[\"cigsPerDay\"].min())\n",
    "print(df2[\"cigsPerDay\"].max())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(df2[\"BPMeds\"].min())\n",
    "print(df2[\"BPMeds\"].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(df2[\"prevalentStroke\"].min())\n",
    "print(df2[\"prevalentStroke\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(df2[\"prevalentHyp\"].min())\n",
    "print(df2[\"prevalentHyp\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(df2[\"diabetes\"].min())\n",
    "print(df2[\"diabetes\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107.0\n",
      "696.0\n"
     ]
    }
   ],
   "source": [
    "print(df2[\"totChol\"].min())\n",
    "print(df2[\"totChol\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>4240.000000</td>\n",
       "      <td>4240.000000</td>\n",
       "      <td>4211.000000</td>\n",
       "      <td>4187.000000</td>\n",
       "      <td>4240.000000</td>\n",
       "      <td>4240.000000</td>\n",
       "      <td>4240.000000</td>\n",
       "      <td>4190.000000</td>\n",
       "      <td>4240.000000</td>\n",
       "      <td>4221.000000</td>\n",
       "      <td>4239.000000</td>\n",
       "      <td>3852.000000</td>\n",
       "      <td>4240.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.429245</td>\n",
       "      <td>49.580189</td>\n",
       "      <td>9.005937</td>\n",
       "      <td>0.029615</td>\n",
       "      <td>0.005896</td>\n",
       "      <td>0.310613</td>\n",
       "      <td>0.025708</td>\n",
       "      <td>236.699523</td>\n",
       "      <td>132.354599</td>\n",
       "      <td>25.800801</td>\n",
       "      <td>75.878981</td>\n",
       "      <td>81.963655</td>\n",
       "      <td>0.151887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.495027</td>\n",
       "      <td>8.572942</td>\n",
       "      <td>11.922462</td>\n",
       "      <td>0.169544</td>\n",
       "      <td>0.076569</td>\n",
       "      <td>0.462799</td>\n",
       "      <td>0.158280</td>\n",
       "      <td>44.591284</td>\n",
       "      <td>22.033300</td>\n",
       "      <td>4.079840</td>\n",
       "      <td>12.025348</td>\n",
       "      <td>23.954335</td>\n",
       "      <td>0.358953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>83.500000</td>\n",
       "      <td>15.540000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>23.070000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>234.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>25.400000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>28.040000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>696.000000</td>\n",
       "      <td>295.000000</td>\n",
       "      <td>56.800000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               sex          age   cigsPerDay       BPMeds  prevalentStroke  \\\n",
       "count  4240.000000  4240.000000  4211.000000  4187.000000      4240.000000   \n",
       "mean      0.429245    49.580189     9.005937     0.029615         0.005896   \n",
       "std       0.495027     8.572942    11.922462     0.169544         0.076569   \n",
       "min       0.000000    32.000000     0.000000     0.000000         0.000000   \n",
       "25%       0.000000    42.000000     0.000000     0.000000         0.000000   \n",
       "50%       0.000000    49.000000     0.000000     0.000000         0.000000   \n",
       "75%       1.000000    56.000000    20.000000     0.000000         0.000000   \n",
       "max       1.000000    70.000000    70.000000     1.000000         1.000000   \n",
       "\n",
       "       prevalentHyp     diabetes      totChol        sysBP          BMI  \\\n",
       "count   4240.000000  4240.000000  4190.000000  4240.000000  4221.000000   \n",
       "mean       0.310613     0.025708   236.699523   132.354599    25.800801   \n",
       "std        0.462799     0.158280    44.591284    22.033300     4.079840   \n",
       "min        0.000000     0.000000   107.000000    83.500000    15.540000   \n",
       "25%        0.000000     0.000000   206.000000   117.000000    23.070000   \n",
       "50%        0.000000     0.000000   234.000000   128.000000    25.400000   \n",
       "75%        1.000000     0.000000   263.000000   144.000000    28.040000   \n",
       "max        1.000000     1.000000   696.000000   295.000000    56.800000   \n",
       "\n",
       "         heartRate      glucose   TenYearCHD  \n",
       "count  4239.000000  3852.000000  4240.000000  \n",
       "mean     75.878981    81.963655     0.151887  \n",
       "std      12.025348    23.954335     0.358953  \n",
       "min      44.000000    40.000000     0.000000  \n",
       "25%      68.000000    71.000000     0.000000  \n",
       "50%      75.000000    78.000000     0.000000  \n",
       "75%      83.000000    87.000000     0.000000  \n",
       "max     143.000000   394.000000     1.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295.0\n",
      "83.5\n"
     ]
    }
   ],
   "source": [
    "#systolic: less than 120 mm Hg diastolic: less than 80 mm Hg\n",
    "print(df2[\"sysBP\"].max())\n",
    "print(df2[\"sysBP\"].min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.8\n",
      "15.54\n"
     ]
    }
   ],
   "source": [
    "#Adult BMI Calculator 18.5â€”24.9\tNormal\n",
    "print(df2[\"BMI\"].max())\n",
    "print(df2[\"BMI\"].min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143.0\n",
      "44.0\n"
     ]
    }
   ],
   "source": [
    "#A normal resting heart rate for adults ranges from 60 to 100 beats per minute\n",
    "print(df2[\"heartRate\"].max())\n",
    "print(df2[\"heartRate\"].min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394.0\n",
      "40.0\n"
     ]
    }
   ],
   "source": [
    "#Normal blood glucose level (while fasting) range within 70 to 99 mg/dL (3.9 to 5.5 mmol/L)\n",
    "print(df2[\"glucose\"].max())\n",
    "print(df2[\"glucose\"].min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex                  0\n",
       "age                  0\n",
       "cigsPerDay          29\n",
       "BPMeds              53\n",
       "prevalentStroke      0\n",
       "prevalentHyp         0\n",
       "diabetes             0\n",
       "totChol             50\n",
       "sysBP                0\n",
       "BMI                 19\n",
       "heartRate            1\n",
       "glucose            388\n",
       "TenYearCHD           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#handle missing  values ,outliers and duplicated data\n",
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4240, 13)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex  age  cigsPerDay  BPMeds  prevalentStroke  prevalentHyp  diabetes  \\\n",
       "0    1   39         0.0     0.0                0             0         0   \n",
       "1    0   46         0.0     0.0                0             0         0   \n",
       "2    1   48        20.0     0.0                0             0         0   \n",
       "3    0   61        30.0     0.0                0             1         0   \n",
       "4    0   46        23.0     0.0                0             0         0   \n",
       "\n",
       "   totChol  sysBP    BMI  heartRate  glucose  TenYearCHD  \n",
       "0    195.0  106.0  26.97       80.0     77.0           0  \n",
       "1    250.0  121.0  28.73       95.0     76.0           0  \n",
       "2    245.0  127.5  25.34       75.0     70.0           0  \n",
       "3    225.0  150.0  28.58       65.0    103.0           1  \n",
       "4    285.0  130.0  23.10       85.0     85.0           0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.dropna(subset=[\"heartRate\"],inplace=True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex                  0\n",
       "age                  0\n",
       "cigsPerDay          29\n",
       "BPMeds              53\n",
       "prevalentStroke      0\n",
       "prevalentHyp         0\n",
       "diabetes             0\n",
       "totChol             50\n",
       "sysBP                0\n",
       "BMI                 19\n",
       "heartRate            0\n",
       "glucose            388\n",
       "TenYearCHD           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex                  0.000\n",
       "age                 49.000\n",
       "cigsPerDay           0.000\n",
       "BPMeds               0.000\n",
       "prevalentStroke      0.000\n",
       "prevalentHyp         0.000\n",
       "diabetes             0.000\n",
       "totChol            234.000\n",
       "sysBP              128.000\n",
       "BMI                 25.395\n",
       "heartRate           75.000\n",
       "glucose             78.000\n",
       "TenYearCHD           0.000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handle the missing values \n",
    "#replace the missing values by the median value\n",
    "import numpy as np\n",
    "df2[\"cigsPerDay\"]=df2[\"cigsPerDay\"].replace(np.nan,df2[\"cigsPerDay\"].median())\n",
    "df2[\"BPMeds\"]=df2[\"BPMeds\"].replace(np.nan,df2[\"BPMeds\"].median())\n",
    "df2[\"totChol\"]=df2[\"totChol\"].replace(np.nan,df2['totChol'].median())\n",
    "df2[\"BMI\"]=df2[\"BMI\"].replace(np.nan,df2[\"BMI\"].median())\n",
    "df2[\"glucose\"]=df2['glucose'].replace(np.nan,df2[\"glucose\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex                0\n",
       "age                0\n",
       "cigsPerDay         0\n",
       "BPMeds             0\n",
       "prevalentStroke    0\n",
       "prevalentHyp       0\n",
       "diabetes           0\n",
       "totChol            0\n",
       "sysBP              0\n",
       "BMI                0\n",
       "heartRate          0\n",
       "glucose            0\n",
       "TenYearCHD         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [sex, age, cigsPerDay, BPMeds, prevalentStroke, prevalentHyp, diabetes, totChol, sysBP, BMI, heartRate, glucose, TenYearCHD]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [sex, age, cigsPerDay, BPMeds, prevalentStroke, prevalentHyp, diabetes, totChol, sysBP, BMI, heartRate, glucose, TenYearCHD]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#outliers detection and removal\n",
    "#it is a value which exceeds the range\n",
    "#ex-let say by mistakly age of a person entered as 2000\n",
    "#so it is known as outliers\n",
    "print(df2[df2[\"age\"]<10])\n",
    "print(df2[df2[\"age\"]>100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [sex, age, cigsPerDay, BPMeds, prevalentStroke, prevalentHyp, diabetes, totChol, sysBP, BMI, heartRate, glucose, TenYearCHD]\n",
       "Index: []"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2[\"BPMeds\"]<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1111</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>600.0</td>\n",
       "      <td>159.5</td>\n",
       "      <td>28.27</td>\n",
       "      <td>78.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3160</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>696.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>24.44</td>\n",
       "      <td>95.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex  age  cigsPerDay  BPMeds  prevalentStroke  prevalentHyp  diabetes  \\\n",
       "1111    0   52         0.0     0.0                0             1         1   \n",
       "3160    1   51         9.0     0.0                0             1         0   \n",
       "\n",
       "      totChol  sysBP    BMI  heartRate  glucose  TenYearCHD  \n",
       "1111    600.0  159.5  28.27       78.0    140.0           1  \n",
       "3160    696.0  157.0  24.44       95.0     84.0           0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2[\"totChol\"]>500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>22.90</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1111</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>600.0</td>\n",
       "      <td>159.5</td>\n",
       "      <td>28.27</td>\n",
       "      <td>78.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3160</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>696.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>24.44</td>\n",
       "      <td>95.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3474</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>453.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>28.89</td>\n",
       "      <td>90.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex  age  cigsPerDay  BPMeds  prevalentStroke  prevalentHyp  diabetes  \\\n",
       "194     0   42         0.0     0.0                0             0         0   \n",
       "1111    0   52         0.0     0.0                0             1         1   \n",
       "3160    1   51         9.0     0.0                0             1         0   \n",
       "3474    1   42        15.0     0.0                0             1         0   \n",
       "\n",
       "      totChol  sysBP    BMI  heartRate  glucose  TenYearCHD  \n",
       "194     464.0  128.0  22.90       72.0     72.0           1  \n",
       "1111    600.0  159.5  28.27       78.0    140.0           1  \n",
       "3160    696.0  157.0  24.44       95.0     84.0           0  \n",
       "3474    453.0  158.0  28.89       90.0    110.0           0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2[\"totChol\"]>450]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3352\n"
     ]
    }
   ],
   "source": [
    "print(len(df2[df2[\"totChol\"]>200]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "print(len(df2[df2[\"sysBP\"]>200]))\n",
    "print(len(df2[df2[\"cigsPerDay\"]>50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>45.80</td>\n",
       "      <td>80.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>249</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>180.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>44.27</td>\n",
       "      <td>88.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>433</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>45.79</td>\n",
       "      <td>110.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>44.09</td>\n",
       "      <td>55.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>833</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>248.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>43.30</td>\n",
       "      <td>107.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>43.69</td>\n",
       "      <td>80.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1525</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>44.55</td>\n",
       "      <td>70.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2162</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>44.71</td>\n",
       "      <td>110.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2307</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>197.5</td>\n",
       "      <td>43.48</td>\n",
       "      <td>68.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2657</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>56.80</td>\n",
       "      <td>90.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3927</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>51.28</td>\n",
       "      <td>80.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4228</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>260.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>43.67</td>\n",
       "      <td>85.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex  age  cigsPerDay  BPMeds  prevalentStroke  prevalentHyp  diabetes  \\\n",
       "78      0   45         0.0     0.0                0             1         0   \n",
       "249     0   60        20.0     0.0                0             0         1   \n",
       "433     0   45         0.0     0.0                0             1         0   \n",
       "750     0   67         0.0     1.0                0             1         0   \n",
       "833     0   53         0.0     0.0                0             1         1   \n",
       "894     0   42        20.0     0.0                0             1         0   \n",
       "1525    0   44         0.0     0.0                0             1         0   \n",
       "2162    0   66         0.0     0.0                0             1         0   \n",
       "2307    0   37         1.0     0.0                0             1         0   \n",
       "2657    0   55         0.0     0.0                0             1         0   \n",
       "3927    0   61         0.0     1.0                1             1         0   \n",
       "4228    0   50         0.0     0.0                0             1         1   \n",
       "\n",
       "      totChol  sysBP    BMI  heartRate  glucose  TenYearCHD  \n",
       "78      183.0  151.0  45.80       80.0     63.0           0  \n",
       "249     180.0  200.0  44.27       88.0    150.0           0  \n",
       "433     226.0  180.0  45.79      110.0     78.0           0  \n",
       "750     251.0  192.0  44.09       55.0     62.0           0  \n",
       "833     248.0  200.0  43.30      107.0    130.0           1  \n",
       "894     199.0  141.0  43.69       80.0     60.0           1  \n",
       "1525    169.0  179.0  44.55       70.0     77.0           0  \n",
       "2162    212.0  220.0  44.71      110.0     95.0           0  \n",
       "2307    274.0  197.5  43.48       68.0     94.0           0  \n",
       "2657    208.0  190.0  56.80       90.0     86.0           1  \n",
       "3927    225.0  194.0  51.28       80.0    103.0           0  \n",
       "4228    260.0  190.0  43.67       85.0    260.0           0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2[\"BMI\"]>43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#heart rate >125\n",
    "len(df2[df2[\"heartRate\"]>125])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df2[df2[\"glucose\"]>200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes the outtliers\n",
    "df2=df2[~(df2['totChol']>450)]\n",
    "df2=df2[~(df2['sysBP']>450)]\n",
    "df2=df2[~(df2['BMI']>450)]\n",
    "df2=df2[~(df2['heartRate']>450)]\n",
    "df2=df2[~(df2[\"glucose\"]>200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4201, 13)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find duplicates from the dataset\n",
    "len(df2[df2.duplicated()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so our dataset has no dulpicate value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>4201.000000</td>\n",
       "      <td>4201.000000</td>\n",
       "      <td>4201.000000</td>\n",
       "      <td>4201.000000</td>\n",
       "      <td>4201.000000</td>\n",
       "      <td>4201.000000</td>\n",
       "      <td>4201.000000</td>\n",
       "      <td>4201.000000</td>\n",
       "      <td>4201.000000</td>\n",
       "      <td>4201.000000</td>\n",
       "      <td>4201.000000</td>\n",
       "      <td>4201.000000</td>\n",
       "      <td>4201.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.428707</td>\n",
       "      <td>49.532254</td>\n",
       "      <td>8.964770</td>\n",
       "      <td>0.028565</td>\n",
       "      <td>0.005713</td>\n",
       "      <td>0.308022</td>\n",
       "      <td>0.017615</td>\n",
       "      <td>236.251845</td>\n",
       "      <td>132.159843</td>\n",
       "      <td>25.778757</td>\n",
       "      <td>75.837420</td>\n",
       "      <td>80.034992</td>\n",
       "      <td>0.147584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.494950</td>\n",
       "      <td>8.572324</td>\n",
       "      <td>11.916063</td>\n",
       "      <td>0.166599</td>\n",
       "      <td>0.075377</td>\n",
       "      <td>0.461731</td>\n",
       "      <td>0.131562</td>\n",
       "      <td>43.125403</td>\n",
       "      <td>21.793705</td>\n",
       "      <td>4.050005</td>\n",
       "      <td>12.023191</td>\n",
       "      <td>14.139407</td>\n",
       "      <td>0.354729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>83.500000</td>\n",
       "      <td>15.540000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>23.070000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>234.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>25.395000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>262.000000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>27.990000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>439.000000</td>\n",
       "      <td>295.000000</td>\n",
       "      <td>56.800000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               sex          age   cigsPerDay       BPMeds  prevalentStroke  \\\n",
       "count  4201.000000  4201.000000  4201.000000  4201.000000      4201.000000   \n",
       "mean      0.428707    49.532254     8.964770     0.028565         0.005713   \n",
       "std       0.494950     8.572324    11.916063     0.166599         0.075377   \n",
       "min       0.000000    32.000000     0.000000     0.000000         0.000000   \n",
       "25%       0.000000    42.000000     0.000000     0.000000         0.000000   \n",
       "50%       0.000000    49.000000     0.000000     0.000000         0.000000   \n",
       "75%       1.000000    56.000000    20.000000     0.000000         0.000000   \n",
       "max       1.000000    70.000000    70.000000     1.000000         1.000000   \n",
       "\n",
       "       prevalentHyp     diabetes      totChol        sysBP          BMI  \\\n",
       "count   4201.000000  4201.000000  4201.000000  4201.000000  4201.000000   \n",
       "mean       0.308022     0.017615   236.251845   132.159843    25.778757   \n",
       "std        0.461731     0.131562    43.125403    21.793705     4.050005   \n",
       "min        0.000000     0.000000   107.000000    83.500000    15.540000   \n",
       "25%        0.000000     0.000000   206.000000   117.000000    23.070000   \n",
       "50%        0.000000     0.000000   234.000000   128.000000    25.395000   \n",
       "75%        1.000000     0.000000   262.000000   143.500000    27.990000   \n",
       "max        1.000000     1.000000   439.000000   295.000000    56.800000   \n",
       "\n",
       "         heartRate      glucose   TenYearCHD  \n",
       "count  4201.000000  4201.000000  4201.000000  \n",
       "mean     75.837420    80.034992     0.147584  \n",
       "std      12.023191    14.139407     0.354729  \n",
       "min      44.000000    40.000000     0.000000  \n",
       "25%      68.000000    72.000000     0.000000  \n",
       "50%      75.000000    78.000000     0.000000  \n",
       "75%      83.000000    85.000000     0.000000  \n",
       "max     143.000000   193.000000     1.000000  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#describe the dataset\n",
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "df2.hist(bins=50,figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4235</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>84.0</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4236</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>19.16</td>\n",
       "      <td>86.0</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4237</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>133.5</td>\n",
       "      <td>21.47</td>\n",
       "      <td>80.0</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4238</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>25.60</td>\n",
       "      <td>67.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4239</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>20.91</td>\n",
       "      <td>85.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4201 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex  age  cigsPerDay  BPMeds  prevalentStroke  prevalentHyp  diabetes  \\\n",
       "0       1   39         0.0     0.0                0             0         0   \n",
       "1       0   46         0.0     0.0                0             0         0   \n",
       "2       1   48        20.0     0.0                0             0         0   \n",
       "3       0   61        30.0     0.0                0             1         0   \n",
       "4       0   46        23.0     0.0                0             0         0   \n",
       "...   ...  ...         ...     ...              ...           ...       ...   \n",
       "4235    0   48        20.0     0.0                0             0         0   \n",
       "4236    0   44        15.0     0.0                0             0         0   \n",
       "4237    0   52         0.0     0.0                0             0         0   \n",
       "4238    1   40         0.0     0.0                0             1         0   \n",
       "4239    0   39        30.0     0.0                0             0         0   \n",
       "\n",
       "      totChol  sysBP    BMI  heartRate  glucose  \n",
       "0       195.0  106.0  26.97       80.0     77.0  \n",
       "1       250.0  121.0  28.73       95.0     76.0  \n",
       "2       245.0  127.5  25.34       75.0     70.0  \n",
       "3       225.0  150.0  28.58       65.0    103.0  \n",
       "4       285.0  130.0  23.10       85.0     85.0  \n",
       "...       ...    ...    ...        ...      ...  \n",
       "4235    248.0  131.0  22.00       84.0     86.0  \n",
       "4236    210.0  126.5  19.16       86.0     78.0  \n",
       "4237    269.0  133.5  21.47       80.0    107.0  \n",
       "4238    185.0  141.0  25.60       67.0     72.0  \n",
       "4239    196.0  133.0  20.91       85.0     80.0  \n",
       "\n",
       "[4201 rows x 12 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df2.drop(columns=[\"TenYearCHD\"])\n",
    "Y=df2[\"TenYearCHD\"]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3360, 12)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split the dataset for training and testing the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=5)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3360,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(841, 12)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(841,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use standard scaler  to scale down the values\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.fit_transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "L=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model\n",
    "L.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test the model by testing data\n",
    "Y_pred=L.predict(X_test)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of logistic regression is: 84.66\n"
     ]
    }
   ],
   "source": [
    "#find accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc_L=accuracy_score(Y_test,Y_pred)\n",
    "acc_L=round(acc_L*100,2)\n",
    "print(\"accuracy of logistic regression is:\",acc_L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN neighbors model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "KNN_C= KNeighborsClassifier(n_neighbors=10 )  \n",
    "#train the model\n",
    "KNN_C.fit(X_train, Y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test the model\n",
    "Y_pred=KNN_C.predict(X_test)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy is : 84.9\n"
     ]
    }
   ],
   "source": [
    "#find accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc_KNN=accuracy_score(Y_test,Y_pred)\n",
    "acc_KNN=round(acc_KNN*100,2)\n",
    "print(\"the accuracy is :\",acc_KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# naive bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "GNB=BernoulliNB()\n",
    "#train the model\n",
    "GNB.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test the model\n",
    "Y_pred=GNB.predict(X_test)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of naive bayes moddel is: 83.12\n"
     ]
    }
   ],
   "source": [
    "#find accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc_NB=accuracy_score(Y_pred,Y_test)\n",
    "acc_NB=round(acc_NB*100,2)\n",
    "print(\"accuracy of naive bayes moddel is:\",acc_NB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# decission tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model=DecisionTreeClassifier(criterion=\"entropy\")\n",
    "#train the model\n",
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(150.19994818928882, 213.93290322580646, 'X[1] <= -0.127\\nentropy = 0.6\\nsamples = 3360\\nvalue = [2869, 491]'),\n",
       " Text(54.20965712639263, 206.91870967741934, 'X[2] <= 0.047\\nentropy = 0.39\\nsamples = 1659\\nvalue = [1532, 127]'),\n",
       " Text(23.76269688820592, 199.90451612903226, 'X[8] <= -0.156\\nentropy = 0.248\\nsamples = 895\\nvalue = [858, 37]'),\n",
       " Text(14.984325777948522, 192.89032258064515, 'X[9] <= -0.182\\nentropy = 0.172\\nsamples = 585\\nvalue = [570, 15]'),\n",
       " Text(6.173799462159048, 185.87612903225806, 'X[11] <= -0.184\\nentropy = 0.094\\nsamples = 332\\nvalue = [328, 4]'),\n",
       " Text(5.14483288513254, 178.86193548387098, 'X[10] <= 0.726\\nentropy = 0.171\\nsamples = 157\\nvalue = [153, 4]'),\n",
       " Text(3.086899731079524, 171.84774193548387, 'X[7] <= -1.538\\nentropy = 0.063\\nsamples = 134\\nvalue = [133, 1]'),\n",
       " Text(2.057933154053016, 164.83354838709678, 'X[11] <= -1.022\\nentropy = 0.414\\nsamples = 12\\nvalue = [11, 1]'),\n",
       " Text(1.028966577026508, 157.81935483870967, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(3.086899731079524, 157.81935483870967, 'entropy = 0.0\\nsamples = 11\\nvalue = [11, 0]'),\n",
       " Text(4.115866308106032, 164.83354838709678, 'entropy = 0.0\\nsamples = 122\\nvalue = [122, 0]'),\n",
       " Text(7.202766039185556, 171.84774193548387, 'X[1] <= -1.177\\nentropy = 0.559\\nsamples = 23\\nvalue = [20, 3]'),\n",
       " Text(6.173799462159048, 164.83354838709678, 'entropy = 0.0\\nsamples = 9\\nvalue = [9, 0]'),\n",
       " Text(8.231732616212064, 164.83354838709678, 'X[9] <= -0.377\\nentropy = 0.75\\nsamples = 14\\nvalue = [11, 3]'),\n",
       " Text(7.202766039185556, 157.81935483870967, 'X[9] <= -0.644\\nentropy = 0.881\\nsamples = 10\\nvalue = [7, 3]'),\n",
       " Text(6.173799462159048, 150.8051612903226, 'X[11] <= -0.253\\nentropy = 0.544\\nsamples = 8\\nvalue = [7, 1]'),\n",
       " Text(5.14483288513254, 143.7909677419355, 'entropy = 0.0\\nsamples = 6\\nvalue = [6, 0]'),\n",
       " Text(7.202766039185556, 143.7909677419355, 'X[9] <= -0.973\\nentropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(6.173799462159048, 136.7767741935484, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(8.231732616212064, 136.7767741935484, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(8.231732616212064, 150.8051612903226, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(9.260699193238572, 157.81935483870967, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(7.202766039185556, 178.86193548387098, 'entropy = 0.0\\nsamples = 175\\nvalue = [175, 0]'),\n",
       " Text(23.794852093737997, 185.87612903225806, 'X[9] <= -0.169\\nentropy = 0.258\\nsamples = 253\\nvalue = [242, 11]'),\n",
       " Text(21.73691893968498, 178.86193548387098, 'X[2] <= -0.708\\nentropy = 0.918\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(20.70795236265847, 171.84774193548387, 'X[1] <= -1.06\\nentropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(19.678985785631966, 164.83354838709678, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(21.73691893968498, 164.83354838709678, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(22.76588551671149, 171.84774193548387, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(25.85278524779101, 178.86193548387098, 'X[10] <= 0.143\\nentropy = 0.224\\nsamples = 250\\nvalue = [241, 9]'),\n",
       " Text(24.823818670764503, 171.84774193548387, 'X[11] <= 2.47\\nentropy = 0.303\\nsamples = 167\\nvalue = [158, 9]'),\n",
       " Text(23.794852093737997, 164.83354838709678, 'X[10] <= 0.059\\nentropy = 0.279\\nsamples = 166\\nvalue = [158, 8]'),\n",
       " Text(19.807606607760277, 157.81935483870967, 'X[7] <= -0.73\\nentropy = 0.23\\nsamples = 161\\nvalue = [155, 6]'),\n",
       " Text(14.920015366884366, 150.8051612903226, 'X[7] <= -0.988\\nentropy = 0.4\\nsamples = 63\\nvalue = [58, 5]'),\n",
       " Text(11.318632347291587, 143.7909677419355, 'X[9] <= 1.204\\nentropy = 0.151\\nsamples = 46\\nvalue = [45, 1]'),\n",
       " Text(10.28966577026508, 136.7767741935484, 'entropy = 0.0\\nsamples = 41\\nvalue = [41, 0]'),\n",
       " Text(12.347598924318095, 136.7767741935484, 'X[1] <= -1.06\\nentropy = 0.722\\nsamples = 5\\nvalue = [4, 1]'),\n",
       " Text(11.318632347291587, 129.76258064516128, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(13.376565501344604, 129.76258064516128, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(18.521398386477145, 143.7909677419355, 'X[10] <= -0.94\\nentropy = 0.787\\nsamples = 17\\nvalue = [13, 4]'),\n",
       " Text(16.463465232424127, 136.7767741935484, 'X[11] <= 0.131\\nentropy = 0.811\\nsamples = 4\\nvalue = [1, 3]'),\n",
       " Text(15.434498655397618, 129.76258064516128, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(17.492431809450636, 129.76258064516128, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(20.57933154053016, 136.7767741935484, 'X[8] <= -0.423\\nentropy = 0.391\\nsamples = 13\\nvalue = [12, 1]'),\n",
       " Text(19.55036496350365, 129.76258064516128, 'entropy = 0.0\\nsamples = 12\\nvalue = [12, 0]'),\n",
       " Text(21.608298117556668, 129.76258064516128, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(24.69519784863619, 150.8051612903226, 'X[11] <= -1.406\\nentropy = 0.082\\nsamples = 98\\nvalue = [97, 1]'),\n",
       " Text(23.666231271609682, 143.7909677419355, 'X[11] <= -1.51\\nentropy = 0.811\\nsamples = 4\\nvalue = [3, 1]'),\n",
       " Text(22.637264694583173, 136.7767741935484, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(24.69519784863619, 136.7767741935484, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(25.7241644256627, 143.7909677419355, 'entropy = 0.0\\nsamples = 94\\nvalue = [94, 0]'),\n",
       " Text(27.782097579715714, 157.81935483870967, 'X[7] <= -0.005\\nentropy = 0.971\\nsamples = 5\\nvalue = [3, 2]'),\n",
       " Text(26.75313100268921, 150.8051612903226, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(28.811064156742223, 150.8051612903226, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(25.85278524779101, 164.83354838709678, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(26.88175182481752, 171.84774193548387, 'entropy = 0.0\\nsamples = 83\\nvalue = [83, 0]'),\n",
       " Text(32.54106799846331, 192.89032258064515, 'X[7] <= -0.66\\nentropy = 0.37\\nsamples = 310\\nvalue = [288, 22]'),\n",
       " Text(28.939684978870535, 185.87612903225806, 'X[1] <= -0.244\\nentropy = 0.089\\nsamples = 89\\nvalue = [88, 1]'),\n",
       " Text(27.91071840184403, 178.86193548387098, 'entropy = 0.0\\nsamples = 79\\nvalue = [79, 0]'),\n",
       " Text(29.968651555897043, 178.86193548387098, 'X[0] <= 0.144\\nentropy = 0.469\\nsamples = 10\\nvalue = [9, 1]'),\n",
       " Text(28.939684978870535, 171.84774193548387, 'entropy = 0.0\\nsamples = 6\\nvalue = [6, 0]'),\n",
       " Text(30.997618132923552, 171.84774193548387, 'X[9] <= 0.528\\nentropy = 0.811\\nsamples = 4\\nvalue = [3, 1]'),\n",
       " Text(29.968651555897043, 164.83354838709678, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(32.02658470995006, 164.83354838709678, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(36.14245101805609, 185.87612903225806, 'X[3] <= 2.879\\nentropy = 0.453\\nsamples = 221\\nvalue = [200, 21]'),\n",
       " Text(34.084517864003075, 178.86193548387098, 'X[11] <= -0.742\\nentropy = 0.428\\nsamples = 217\\nvalue = [198, 19]'),\n",
       " Text(33.055551286976566, 171.84774193548387, 'entropy = 0.0\\nsamples = 28\\nvalue = [28, 0]'),\n",
       " Text(35.113484441029584, 171.84774193548387, 'X[10] <= -1.19\\nentropy = 0.471\\nsamples = 189\\nvalue = [170, 19]'),\n",
       " Text(34.084517864003075, 164.83354838709678, 'entropy = 0.0\\nsamples = 18\\nvalue = [18, 0]'),\n",
       " Text(36.14245101805609, 164.83354838709678, 'X[10] <= 0.726\\nentropy = 0.503\\nsamples = 171\\nvalue = [152, 19]'),\n",
       " Text(33.055551286976566, 157.81935483870967, 'X[8] <= -0.133\\nentropy = 0.583\\nsamples = 122\\nvalue = [105, 17]'),\n",
       " Text(30.997618132923552, 150.8051612903226, 'X[11] <= -0.218\\nentropy = 0.918\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(29.968651555897043, 143.7909677419355, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(32.02658470995006, 143.7909677419355, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(35.113484441029584, 150.8051612903226, 'X[7] <= 2.629\\nentropy = 0.547\\nsamples = 119\\nvalue = [104, 15]'),\n",
       " Text(34.084517864003075, 143.7909677419355, 'X[7] <= -0.59\\nentropy = 0.525\\nsamples = 118\\nvalue = [104, 14]'),\n",
       " Text(32.02658470995006, 136.7767741935484, 'X[0] <= 0.144\\nentropy = 1.0\\nsamples = 4\\nvalue = [2, 2]'),\n",
       " Text(30.997618132923552, 129.76258064516128, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(33.055551286976566, 129.76258064516128, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(36.14245101805609, 136.7767741935484, 'X[9] <= -0.688\\nentropy = 0.485\\nsamples = 114\\nvalue = [102, 12]'),\n",
       " Text(35.113484441029584, 129.76258064516128, 'entropy = 0.0\\nsamples = 19\\nvalue = [19, 0]'),\n",
       " Text(37.1714175950826, 129.76258064516128, 'X[11] <= -0.603\\nentropy = 0.547\\nsamples = 95\\nvalue = [83, 12]'),\n",
       " Text(35.113484441029584, 122.7483870967742, 'X[0] <= 0.144\\nentropy = 0.985\\nsamples = 7\\nvalue = [4, 3]'),\n",
       " Text(34.084517864003075, 115.7341935483871, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(36.14245101805609, 115.7341935483871, 'X[9] <= -0.122\\nentropy = 0.811\\nsamples = 4\\nvalue = [1, 3]'),\n",
       " Text(35.113484441029584, 108.72, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(37.1714175950826, 108.72, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(39.22935074913561, 122.7483870967742, 'X[11] <= -0.323\\nentropy = 0.476\\nsamples = 88\\nvalue = [79, 9]'),\n",
       " Text(38.20038417210911, 115.7341935483871, 'entropy = 0.0\\nsamples = 24\\nvalue = [24, 0]'),\n",
       " Text(40.25831732616212, 115.7341935483871, 'X[9] <= 1.304\\nentropy = 0.586\\nsamples = 64\\nvalue = [55, 9]'),\n",
       " Text(39.22935074913561, 108.72, 'X[10] <= -0.815\\nentropy = 0.696\\nsamples = 48\\nvalue = [39, 9]'),\n",
       " Text(37.1714175950826, 101.70580645161291, 'X[1] <= -0.594\\nentropy = 0.971\\nsamples = 5\\nvalue = [2, 3]'),\n",
       " Text(36.14245101805609, 94.69161290322582, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(38.20038417210911, 94.69161290322582, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(41.28728390318863, 101.70580645161291, 'X[11] <= 0.166\\nentropy = 0.583\\nsamples = 43\\nvalue = [37, 6]'),\n",
       " Text(40.25831732616212, 94.69161290322582, 'X[10] <= -0.107\\nentropy = 0.845\\nsamples = 22\\nvalue = [16, 6]'),\n",
       " Text(39.22935074913561, 87.67741935483872, 'entropy = 0.0\\nsamples = 8\\nvalue = [8, 0]'),\n",
       " Text(41.28728390318863, 87.67741935483872, 'X[7] <= 0.007\\nentropy = 0.985\\nsamples = 14\\nvalue = [8, 6]'),\n",
       " Text(39.22935074913561, 80.6632258064516, 'X[9] <= -0.125\\nentropy = 0.722\\nsamples = 5\\nvalue = [1, 4]'),\n",
       " Text(38.20038417210911, 73.64903225806452, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(40.25831732616212, 73.64903225806452, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 4]'),\n",
       " Text(43.34521705724165, 80.6632258064516, 'X[8] <= 0.911\\nentropy = 0.764\\nsamples = 9\\nvalue = [7, 2]'),\n",
       " Text(42.31625048021514, 73.64903225806452, 'entropy = 0.0\\nsamples = 6\\nvalue = [6, 0]'),\n",
       " Text(44.37418363426816, 73.64903225806452, 'X[9] <= -0.465\\nentropy = 0.918\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(43.34521705724165, 66.63483870967744, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(45.403150211294665, 66.63483870967744, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(42.31625048021514, 94.69161290322582, 'entropy = 0.0\\nsamples = 21\\nvalue = [21, 0]'),\n",
       " Text(41.28728390318863, 108.72, 'entropy = 0.0\\nsamples = 16\\nvalue = [16, 0]'),\n",
       " Text(36.14245101805609, 143.7909677419355, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(39.22935074913561, 157.81935483870967, 'X[0] <= 0.144\\nentropy = 0.246\\nsamples = 49\\nvalue = [47, 2]'),\n",
       " Text(38.20038417210911, 150.8051612903226, 'entropy = 0.0\\nsamples = 34\\nvalue = [34, 0]'),\n",
       " Text(40.25831732616212, 150.8051612903226, 'X[9] <= 1.821\\nentropy = 0.567\\nsamples = 15\\nvalue = [13, 2]'),\n",
       " Text(39.22935074913561, 143.7909677419355, 'X[8] <= 0.737\\nentropy = 0.371\\nsamples = 14\\nvalue = [13, 1]'),\n",
       " Text(38.20038417210911, 136.7767741935484, 'entropy = 0.0\\nsamples = 12\\nvalue = [12, 0]'),\n",
       " Text(40.25831732616212, 136.7767741935484, 'X[11] <= 0.201\\nentropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(39.22935074913561, 129.76258064516128, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(41.28728390318863, 129.76258064516128, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(41.28728390318863, 143.7909677419355, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(38.20038417210911, 178.86193548387098, 'X[1] <= -0.594\\nentropy = 1.0\\nsamples = 4\\nvalue = [2, 2]'),\n",
       " Text(37.1714175950826, 171.84774193548387, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(39.22935074913561, 171.84774193548387, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(84.65661736457933, 199.90451612903226, 'X[8] <= 0.03\\nentropy = 0.523\\nsamples = 764\\nvalue = [674, 90]'),\n",
       " Text(70.99869381482905, 192.89032258064515, 'X[7] <= -0.122\\nentropy = 0.443\\nsamples = 565\\nvalue = [513, 52]'),\n",
       " Text(61.86661544371879, 185.87612903225806, 'X[1] <= -0.361\\nentropy = 0.305\\nsamples = 331\\nvalue = [313, 18]'),\n",
       " Text(59.29419900115252, 178.86193548387098, 'X[9] <= 0.093\\nentropy = 0.244\\nsamples = 297\\nvalue = [285, 12]'),\n",
       " Text(58.26523242412601, 171.84774193548387, 'X[9] <= 0.076\\nentropy = 0.284\\nsamples = 243\\nvalue = [231, 12]'),\n",
       " Text(57.2362658470995, 164.83354838709678, 'X[10] <= 0.809\\nentropy = 0.267\\nsamples = 242\\nvalue = [231, 11]'),\n",
       " Text(56.207299270072994, 157.81935483870967, 'X[8] <= -1.328\\nentropy = 0.306\\nsamples = 201\\nvalue = [190, 11]'),\n",
       " Text(55.17833269304649, 150.8051612903226, 'entropy = 0.0\\nsamples = 29\\nvalue = [29, 0]'),\n",
       " Text(57.2362658470995, 150.8051612903226, 'X[8] <= -0.26\\nentropy = 0.343\\nsamples = 172\\nvalue = [161, 11]'),\n",
       " Text(56.207299270072994, 143.7909677419355, 'X[8] <= -0.353\\nentropy = 0.386\\nsamples = 146\\nvalue = [135, 11]'),\n",
       " Text(53.63488282750673, 136.7767741935484, 'X[8] <= -0.504\\nentropy = 0.344\\nsamples = 140\\nvalue = [131, 9]'),\n",
       " Text(52.60591625048022, 129.76258064516128, 'X[8] <= -0.551\\nentropy = 0.389\\nsamples = 118\\nvalue = [109, 9]'),\n",
       " Text(50.5479830964272, 122.7483870967742, 'X[8] <= -0.713\\nentropy = 0.335\\nsamples = 113\\nvalue = [106, 7]'),\n",
       " Text(49.519016519400694, 115.7341935483871, 'X[8] <= -0.736\\nentropy = 0.432\\nsamples = 79\\nvalue = [72, 7]'),\n",
       " Text(48.490049942374185, 108.72, 'X[7] <= -1.398\\nentropy = 0.391\\nsamples = 78\\nvalue = [72, 6]'),\n",
       " Text(46.432116788321174, 101.70580645161291, 'X[8] <= -0.957\\nentropy = 0.75\\nsamples = 14\\nvalue = [11, 3]'),\n",
       " Text(45.403150211294665, 94.69161290322582, 'entropy = 0.0\\nsamples = 9\\nvalue = [9, 0]'),\n",
       " Text(47.461083365347676, 94.69161290322582, 'X[10] <= -0.357\\nentropy = 0.971\\nsamples = 5\\nvalue = [2, 3]'),\n",
       " Text(46.432116788321174, 87.67741935483872, 'X[11] <= -0.253\\nentropy = 0.918\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(45.403150211294665, 80.6632258064516, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(47.461083365347676, 80.6632258064516, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(48.490049942374185, 87.67741935483872, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(50.5479830964272, 101.70580645161291, 'X[1] <= -1.177\\nentropy = 0.273\\nsamples = 64\\nvalue = [61, 3]'),\n",
       " Text(49.519016519400694, 94.69161290322582, 'entropy = 0.0\\nsamples = 28\\nvalue = [28, 0]'),\n",
       " Text(51.57694967345371, 94.69161290322582, 'X[7] <= -0.824\\nentropy = 0.414\\nsamples = 36\\nvalue = [33, 3]'),\n",
       " Text(50.5479830964272, 87.67741935483872, 'entropy = 0.0\\nsamples = 12\\nvalue = [12, 0]'),\n",
       " Text(52.60591625048022, 87.67741935483872, 'X[2] <= 0.299\\nentropy = 0.544\\nsamples = 24\\nvalue = [21, 3]'),\n",
       " Text(51.57694967345371, 80.6632258064516, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(53.63488282750673, 80.6632258064516, 'X[1] <= -0.943\\nentropy = 0.426\\nsamples = 23\\nvalue = [21, 2]'),\n",
       " Text(52.60591625048022, 73.64903225806452, 'X[9] <= -1.402\\nentropy = 0.863\\nsamples = 7\\nvalue = [5, 2]'),\n",
       " Text(51.57694967345371, 66.63483870967744, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(53.63488282750673, 66.63483870967744, 'X[9] <= -0.346\\nentropy = 0.65\\nsamples = 6\\nvalue = [5, 1]'),\n",
       " Text(52.60591625048022, 59.62064516129033, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(54.66384940453324, 59.62064516129033, 'X[11] <= -0.498\\nentropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(53.63488282750673, 52.60645161290324, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(55.69281598155974, 52.60645161290324, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(54.66384940453324, 73.64903225806452, 'entropy = 0.0\\nsamples = 16\\nvalue = [16, 0]'),\n",
       " Text(50.5479830964272, 108.72, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(51.57694967345371, 115.7341935483871, 'entropy = 0.0\\nsamples = 34\\nvalue = [34, 0]'),\n",
       " Text(54.66384940453324, 122.7483870967742, 'X[9] <= -0.661\\nentropy = 0.971\\nsamples = 5\\nvalue = [3, 2]'),\n",
       " Text(53.63488282750673, 115.7341935483871, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(55.69281598155974, 115.7341935483871, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(54.66384940453324, 129.76258064516128, 'entropy = 0.0\\nsamples = 22\\nvalue = [22, 0]'),\n",
       " Text(58.779715712639266, 136.7767741935484, 'X[11] <= -0.638\\nentropy = 0.918\\nsamples = 6\\nvalue = [4, 2]'),\n",
       " Text(57.75074913561276, 129.76258064516128, 'X[9] <= -0.703\\nentropy = 0.918\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(56.72178255858625, 122.7483870967742, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(58.779715712639266, 122.7483870967742, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(59.808682289665775, 129.76258064516128, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(58.26523242412601, 143.7909677419355, 'entropy = 0.0\\nsamples = 26\\nvalue = [26, 0]'),\n",
       " Text(58.26523242412601, 157.81935483870967, 'entropy = 0.0\\nsamples = 41\\nvalue = [41, 0]'),\n",
       " Text(59.29419900115252, 164.83354838709678, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(60.32316557817903, 171.84774193548387, 'entropy = 0.0\\nsamples = 54\\nvalue = [54, 0]'),\n",
       " Text(64.43903188628506, 178.86193548387098, 'X[7] <= -1.538\\nentropy = 0.672\\nsamples = 34\\nvalue = [28, 6]'),\n",
       " Text(62.38109873223205, 171.84774193548387, 'X[0] <= 0.144\\nentropy = 0.918\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(61.35213215520554, 164.83354838709678, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(63.410065309258556, 164.83354838709678, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(66.49696504033808, 171.84774193548387, 'X[7] <= -0.672\\nentropy = 0.555\\nsamples = 31\\nvalue = [27, 4]'),\n",
       " Text(65.46799846331157, 164.83354838709678, 'entropy = 0.0\\nsamples = 14\\nvalue = [14, 0]'),\n",
       " Text(67.52593161736459, 164.83354838709678, 'X[7] <= -0.59\\nentropy = 0.787\\nsamples = 17\\nvalue = [13, 4]'),\n",
       " Text(65.46799846331157, 157.81935483870967, 'X[8] <= -0.075\\nentropy = 0.811\\nsamples = 4\\nvalue = [1, 3]'),\n",
       " Text(64.43903188628506, 150.8051612903226, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(66.49696504033808, 150.8051612903226, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(69.5838647714176, 157.81935483870967, 'X[9] <= -1.429\\nentropy = 0.391\\nsamples = 13\\nvalue = [12, 1]'),\n",
       " Text(68.55489819439109, 150.8051612903226, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(70.6128313484441, 150.8051612903226, 'entropy = 0.0\\nsamples = 12\\nvalue = [12, 0]'),\n",
       " Text(80.1307721859393, 185.87612903225806, 'X[6] <= 3.609\\nentropy = 0.598\\nsamples = 234\\nvalue = [200, 34]'),\n",
       " Text(79.1018056089128, 178.86193548387098, 'X[9] <= -1.229\\nentropy = 0.569\\nsamples = 231\\nvalue = [200, 31]'),\n",
       " Text(78.07283903188629, 171.84774193548387, 'entropy = 0.0\\nsamples = 21\\nvalue = [21, 0]'),\n",
       " Text(80.1307721859393, 171.84774193548387, 'X[11] <= -0.952\\nentropy = 0.604\\nsamples = 210\\nvalue = [179, 31]'),\n",
       " Text(75.75766423357665, 164.83354838709678, 'X[10] <= -0.773\\nentropy = 0.894\\nsamples = 29\\nvalue = [20, 9]'),\n",
       " Text(73.69973107952363, 157.81935483870967, 'X[1] <= -1.06\\nentropy = 0.722\\nsamples = 5\\nvalue = [1, 4]'),\n",
       " Text(72.67076450249712, 150.8051612903226, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(74.72869765655014, 150.8051612903226, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 4]'),\n",
       " Text(77.81559738762967, 157.81935483870967, 'X[9] <= 1.417\\nentropy = 0.738\\nsamples = 24\\nvalue = [19, 5]'),\n",
       " Text(76.78663081060316, 150.8051612903226, 'X[7] <= 0.428\\nentropy = 0.667\\nsamples = 23\\nvalue = [19, 4]'),\n",
       " Text(75.75766423357665, 143.7909677419355, 'X[8] <= -0.469\\nentropy = 0.918\\nsamples = 12\\nvalue = [8, 4]'),\n",
       " Text(74.72869765655014, 136.7767741935484, 'X[8] <= -1.049\\nentropy = 0.985\\nsamples = 7\\nvalue = [3, 4]'),\n",
       " Text(73.69973107952363, 129.76258064516128, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(75.75766423357665, 129.76258064516128, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 4]'),\n",
       " Text(76.78663081060316, 136.7767741935484, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
       " Text(77.81559738762967, 143.7909677419355, 'entropy = 0.0\\nsamples = 11\\nvalue = [11, 0]'),\n",
       " Text(78.84456396465617, 150.8051612903226, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(84.50388013830197, 164.83354838709678, 'X[8] <= -0.226\\nentropy = 0.534\\nsamples = 181\\nvalue = [159, 22]'),\n",
       " Text(83.47491356127546, 157.81935483870967, 'X[10] <= -0.69\\nentropy = 0.582\\nsamples = 158\\nvalue = [136, 22]'),\n",
       " Text(80.90249711870919, 150.8051612903226, 'X[9] <= -1.079\\nentropy = 0.206\\nsamples = 31\\nvalue = [30, 1]'),\n",
       " Text(79.87353054168268, 143.7909677419355, 'X[7] <= 1.213\\nentropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(78.84456396465617, 136.7767741935484, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(80.90249711870919, 136.7767741935484, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(81.9314636957357, 143.7909677419355, 'entropy = 0.0\\nsamples = 29\\nvalue = [29, 0]'),\n",
       " Text(86.04733000384172, 150.8051612903226, 'X[5] <= 0.414\\nentropy = 0.647\\nsamples = 127\\nvalue = [106, 21]'),\n",
       " Text(83.98939684978872, 143.7909677419355, 'X[9] <= -1.202\\nentropy = 0.618\\nsamples = 124\\nvalue = [105, 19]'),\n",
       " Text(82.96043027276221, 136.7767741935484, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(85.01836342681521, 136.7767741935484, 'X[11] <= 1.562\\nentropy = 0.601\\nsamples = 123\\nvalue = [105, 18]'),\n",
       " Text(82.96043027276221, 129.76258064516128, 'X[1] <= -1.293\\nentropy = 0.556\\nsamples = 116\\nvalue = [101, 15]'),\n",
       " Text(81.9314636957357, 122.7483870967742, 'entropy = 0.0\\nsamples = 20\\nvalue = [20, 0]'),\n",
       " Text(83.98939684978872, 122.7483870967742, 'X[9] <= -0.972\\nentropy = 0.625\\nsamples = 96\\nvalue = [81, 15]'),\n",
       " Text(82.96043027276221, 115.7341935483871, 'entropy = 0.0\\nsamples = 8\\nvalue = [8, 0]'),\n",
       " Text(85.01836342681521, 115.7341935483871, 'X[9] <= -0.912\\nentropy = 0.659\\nsamples = 88\\nvalue = [73, 15]'),\n",
       " Text(83.98939684978872, 108.72, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(86.04733000384172, 108.72, 'X[7] <= 0.159\\nentropy = 0.613\\nsamples = 86\\nvalue = [73, 13]'),\n",
       " Text(82.96043027276221, 101.70580645161291, 'X[1] <= -0.244\\nentropy = 0.235\\nsamples = 26\\nvalue = [25, 1]'),\n",
       " Text(81.9314636957357, 94.69161290322582, 'entropy = 0.0\\nsamples = 24\\nvalue = [24, 0]'),\n",
       " Text(83.98939684978872, 94.69161290322582, 'X[0] <= 0.144\\nentropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(82.96043027276221, 87.67741935483872, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(85.01836342681521, 87.67741935483872, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(89.13422973492125, 101.70580645161291, 'X[1] <= -0.361\\nentropy = 0.722\\nsamples = 60\\nvalue = [48, 12]'),\n",
       " Text(88.10526315789474, 94.69161290322582, 'X[7] <= 0.183\\nentropy = 0.772\\nsamples = 53\\nvalue = [41, 12]'),\n",
       " Text(87.07629658086823, 87.67741935483872, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(89.13422973492125, 87.67741935483872, 'X[8] <= -0.98\\nentropy = 0.744\\nsamples = 52\\nvalue = [41, 11]'),\n",
       " Text(88.10526315789474, 80.6632258064516, 'entropy = 0.0\\nsamples = 8\\nvalue = [8, 0]'),\n",
       " Text(90.16319631194776, 80.6632258064516, 'X[7] <= 1.903\\nentropy = 0.811\\nsamples = 44\\nvalue = [33, 11]'),\n",
       " Text(89.13422973492125, 73.64903225806452, 'X[10] <= 1.475\\nentropy = 0.849\\nsamples = 40\\nvalue = [29, 11]'),\n",
       " Text(88.10526315789474, 66.63483870967744, 'X[10] <= 1.267\\nentropy = 0.878\\nsamples = 37\\nvalue = [26, 11]'),\n",
       " Text(87.07629658086823, 59.62064516129033, 'X[10] <= 0.684\\nentropy = 0.852\\nsamples = 36\\nvalue = [26, 10]'),\n",
       " Text(86.04733000384172, 52.60645161290324, 'X[10] <= 0.559\\nentropy = 0.896\\nsamples = 32\\nvalue = [22, 10]'),\n",
       " Text(85.01836342681521, 45.59225806451613, 'X[9] <= 0.587\\nentropy = 0.837\\nsamples = 30\\nvalue = [22, 8]'),\n",
       " Text(83.98939684978872, 38.57806451612905, 'X[1] <= -0.943\\nentropy = 0.904\\nsamples = 25\\nvalue = [17, 8]'),\n",
       " Text(81.9314636957357, 31.563870967741934, 'X[10] <= 0.143\\nentropy = 0.985\\nsamples = 7\\nvalue = [3, 4]'),\n",
       " Text(80.90249711870919, 24.54967741935485, 'X[2] <= 0.719\\nentropy = 0.722\\nsamples = 5\\nvalue = [1, 4]'),\n",
       " Text(79.87353054168268, 17.535483870967767, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(81.9314636957357, 17.535483870967767, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 4]'),\n",
       " Text(82.96043027276221, 24.54967741935485, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(86.04733000384172, 31.563870967741934, 'X[8] <= -0.62\\nentropy = 0.764\\nsamples = 18\\nvalue = [14, 4]'),\n",
       " Text(85.01836342681521, 24.54967741935485, 'X[9] <= -0.059\\nentropy = 0.971\\nsamples = 10\\nvalue = [6, 4]'),\n",
       " Text(83.98939684978872, 17.535483870967767, 'X[11] <= 0.48\\nentropy = 0.592\\nsamples = 7\\nvalue = [6, 1]'),\n",
       " Text(82.96043027276221, 10.521290322580654, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
       " Text(85.01836342681521, 10.521290322580654, 'X[7] <= 1.505\\nentropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(83.98939684978872, 3.5070967741935704, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(86.04733000384172, 3.5070967741935704, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(86.04733000384172, 17.535483870967767, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(87.07629658086823, 24.54967741935485, 'entropy = 0.0\\nsamples = 8\\nvalue = [8, 0]'),\n",
       " Text(86.04733000384172, 38.57806451612905, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
       " Text(87.07629658086823, 45.59225806451613, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(88.10526315789474, 52.60645161290324, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(89.13422973492125, 59.62064516129033, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(90.16319631194776, 66.63483870967744, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(91.19216288897427, 73.64903225806452, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(90.16319631194776, 94.69161290322582, 'entropy = 0.0\\nsamples = 7\\nvalue = [7, 0]'),\n",
       " Text(87.07629658086823, 129.76258064516128, 'X[11] <= 2.051\\nentropy = 0.985\\nsamples = 7\\nvalue = [4, 3]'),\n",
       " Text(86.04733000384172, 122.7483870967742, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(88.10526315789474, 122.7483870967742, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(88.10526315789474, 143.7909677419355, 'X[1] <= -0.769\\nentropy = 0.918\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(87.07629658086823, 136.7767741935484, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(89.13422973492125, 136.7767741935484, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(85.53284671532847, 157.81935483870967, 'entropy = 0.0\\nsamples = 23\\nvalue = [23, 0]'),\n",
       " Text(81.15973876296582, 178.86193548387098, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(98.31454091432963, 192.89032258064515, 'X[9] <= -0.974\\nentropy = 0.703\\nsamples = 199\\nvalue = [161, 38]'),\n",
       " Text(93.25009604302728, 185.87612903225806, 'X[7] <= 0.651\\nentropy = 0.995\\nsamples = 24\\nvalue = [13, 11]'),\n",
       " Text(92.22112946600078, 178.86193548387098, 'X[9] <= -1.54\\nentropy = 0.993\\nsamples = 20\\nvalue = [9, 11]'),\n",
       " Text(91.19216288897427, 171.84774193548387, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(93.25009604302728, 171.84774193548387, 'X[8] <= 0.772\\nentropy = 0.937\\nsamples = 17\\nvalue = [6, 11]'),\n",
       " Text(92.22112946600078, 164.83354838709678, 'X[1] <= -0.885\\nentropy = 0.985\\nsamples = 14\\nvalue = [6, 8]'),\n",
       " Text(90.16319631194776, 157.81935483870967, 'X[2] <= 0.719\\nentropy = 0.918\\nsamples = 6\\nvalue = [4, 2]'),\n",
       " Text(89.13422973492125, 150.8051612903226, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(91.19216288897427, 150.8051612903226, 'X[1] <= -1.41\\nentropy = 0.918\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(90.16319631194776, 143.7909677419355, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(92.22112946600078, 143.7909677419355, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(94.2790626200538, 157.81935483870967, 'X[10] <= -0.274\\nentropy = 0.811\\nsamples = 8\\nvalue = [2, 6]'),\n",
       " Text(93.25009604302728, 150.8051612903226, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 4]'),\n",
       " Text(95.3080291970803, 150.8051612903226, 'X[11] <= -0.114\\nentropy = 1.0\\nsamples = 4\\nvalue = [2, 2]'),\n",
       " Text(94.2790626200538, 143.7909677419355, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(96.33699577410681, 143.7909677419355, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(94.2790626200538, 164.83354838709678, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(94.2790626200538, 178.86193548387098, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(103.37898578563197, 185.87612903225806, 'X[7] <= 3.449\\nentropy = 0.62\\nsamples = 175\\nvalue = [148, 27]'),\n",
       " Text(102.35001920860546, 178.86193548387098, 'X[2] <= 0.803\\nentropy = 0.596\\nsamples = 173\\nvalue = [148, 25]'),\n",
       " Text(98.39492892815983, 171.84774193548387, 'X[9] <= 0.383\\nentropy = 0.196\\nsamples = 33\\nvalue = [32, 1]'),\n",
       " Text(97.36596235113332, 164.83354838709678, 'entropy = 0.0\\nsamples = 21\\nvalue = [21, 0]'),\n",
       " Text(99.42389550518634, 164.83354838709678, 'X[9] <= 0.441\\nentropy = 0.414\\nsamples = 12\\nvalue = [11, 1]'),\n",
       " Text(98.39492892815983, 157.81935483870967, 'X[7] <= -0.227\\nentropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(97.36596235113332, 150.8051612903226, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(99.42389550518634, 150.8051612903226, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(100.45286208221285, 157.81935483870967, 'entropy = 0.0\\nsamples = 10\\nvalue = [10, 0]'),\n",
       " Text(106.3051094890511, 171.84774193548387, 'X[8] <= 0.076\\nentropy = 0.661\\nsamples = 140\\nvalue = [116, 24]'),\n",
       " Text(103.53976181329236, 164.83354838709678, 'X[9] <= 0.235\\nentropy = 0.985\\nsamples = 7\\nvalue = [3, 4]'),\n",
       " Text(102.51079523626585, 157.81935483870967, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(104.56872839031887, 157.81935483870967, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 4]'),\n",
       " Text(109.07045716480984, 164.83354838709678, 'X[8] <= 0.238\\nentropy = 0.611\\nsamples = 133\\nvalue = [113, 20]'),\n",
       " Text(106.62666154437188, 157.81935483870967, 'X[9] <= -0.473\\nentropy = 0.211\\nsamples = 30\\nvalue = [29, 1]'),\n",
       " Text(105.59769496734538, 150.8051612903226, 'X[9] <= -0.498\\nentropy = 0.722\\nsamples = 5\\nvalue = [4, 1]'),\n",
       " Text(104.56872839031887, 143.7909677419355, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(106.62666154437188, 143.7909677419355, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(107.6556281213984, 150.8051612903226, 'entropy = 0.0\\nsamples = 25\\nvalue = [25, 0]'),\n",
       " Text(111.5142527852478, 157.81935483870967, 'X[1] <= -1.293\\nentropy = 0.69\\nsamples = 103\\nvalue = [84, 19]'),\n",
       " Text(110.4852862082213, 150.8051612903226, 'entropy = 0.0\\nsamples = 9\\nvalue = [9, 0]'),\n",
       " Text(112.54321936227431, 150.8051612903226, 'X[7] <= 0.475\\nentropy = 0.726\\nsamples = 94\\nvalue = [75, 19]'),\n",
       " Text(108.6845946984249, 143.7909677419355, 'X[11] <= 0.585\\nentropy = 0.602\\nsamples = 68\\nvalue = [58, 10]'),\n",
       " Text(107.6556281213984, 136.7767741935484, 'X[11] <= 0.41\\nentropy = 0.677\\nsamples = 56\\nvalue = [46, 10]'),\n",
       " Text(106.62666154437188, 129.76258064516128, 'X[8] <= 0.54\\nentropy = 0.605\\nsamples = 54\\nvalue = [46, 8]'),\n",
       " Text(103.02527852477911, 122.7483870967742, 'X[8] <= 0.355\\nentropy = 0.9\\nsamples = 19\\nvalue = [13, 6]'),\n",
       " Text(100.9673453707261, 115.7341935483871, 'X[1] <= -1.06\\nentropy = 0.503\\nsamples = 9\\nvalue = [8, 1]'),\n",
       " Text(99.93837879369958, 108.72, 'X[0] <= 0.144\\nentropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(98.90941221667308, 101.70580645161291, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(100.9673453707261, 101.70580645161291, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(101.9963119477526, 108.72, 'entropy = 0.0\\nsamples = 7\\nvalue = [7, 0]'),\n",
       " Text(105.08321167883213, 115.7341935483871, 'X[9] <= -0.282\\nentropy = 1.0\\nsamples = 10\\nvalue = [5, 5]'),\n",
       " Text(104.05424510180562, 108.72, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(106.11217825585864, 108.72, 'X[9] <= 0.537\\nentropy = 0.863\\nsamples = 7\\nvalue = [5, 2]'),\n",
       " Text(105.08321167883213, 101.70580645161291, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(107.14114483288515, 101.70580645161291, 'X[7] <= -0.859\\nentropy = 0.918\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(106.11217825585864, 94.69161290322582, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(108.17011140991166, 94.69161290322582, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(110.22804456396466, 122.7483870967742, 'X[7] <= -0.087\\nentropy = 0.316\\nsamples = 35\\nvalue = [33, 2]'),\n",
       " Text(109.19907798693815, 115.7341935483871, 'entropy = 0.0\\nsamples = 19\\nvalue = [19, 0]'),\n",
       " Text(111.25701114099117, 115.7341935483871, 'X[7] <= -0.005\\nentropy = 0.544\\nsamples = 16\\nvalue = [14, 2]'),\n",
       " Text(110.22804456396466, 108.72, 'X[2] <= 1.138\\nentropy = 0.918\\nsamples = 6\\nvalue = [4, 2]'),\n",
       " Text(109.19907798693815, 101.70580645161291, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(111.25701114099117, 101.70580645161291, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(112.28597771801768, 108.72, 'entropy = 0.0\\nsamples = 10\\nvalue = [10, 0]'),\n",
       " Text(108.6845946984249, 129.76258064516128, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(109.71356127545141, 136.7767741935484, 'entropy = 0.0\\nsamples = 12\\nvalue = [12, 0]'),\n",
       " Text(116.40184402612371, 143.7909677419355, 'X[9] <= -0.101\\nentropy = 0.931\\nsamples = 26\\nvalue = [17, 9]'),\n",
       " Text(115.3728774490972, 136.7767741935484, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
       " Text(117.43081060315022, 136.7767741935484, 'X[11] <= -0.114\\nentropy = 0.985\\nsamples = 21\\nvalue = [12, 9]'),\n",
       " Text(115.3728774490972, 129.76258064516128, 'X[11] <= -0.917\\nentropy = 0.811\\nsamples = 8\\nvalue = [2, 6]'),\n",
       " Text(114.3439108720707, 122.7483870967742, 'X[5] <= 0.414\\nentropy = 0.918\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(113.31494429504419, 115.7341935483871, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(115.3728774490972, 115.7341935483871, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(116.40184402612371, 122.7483870967742, 'entropy = 0.0\\nsamples = 5\\nvalue = [0, 5]'),\n",
       " Text(119.48874375720324, 129.76258064516128, 'X[8] <= 0.691\\nentropy = 0.779\\nsamples = 13\\nvalue = [10, 3]'),\n",
       " Text(118.45977718017673, 122.7483870967742, 'entropy = 0.0\\nsamples = 8\\nvalue = [8, 0]'),\n",
       " Text(120.51771033422975, 122.7483870967742, 'X[8] <= 1.654\\nentropy = 0.971\\nsamples = 5\\nvalue = [2, 3]'),\n",
       " Text(119.48874375720324, 115.7341935483871, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(121.54667691125626, 115.7341935483871, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(104.40795236265848, 178.86193548387098, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(246.190239252185, 206.91870967741934, 'X[8] <= 0.494\\nentropy = 0.749\\nsamples = 1701\\nvalue = [1337, 364]'),\n",
       " Text(191.1585518812428, 199.90451612903226, 'X[1] <= 1.854\\nentropy = 0.629\\nsamples = 1040\\nvalue = [876, 164]'),\n",
       " Text(157.61652750432194, 192.89032258064515, 'X[8] <= -1.084\\nentropy = 0.61\\nsamples = 1005\\nvalue = [854, 151]'),\n",
       " Text(137.62427967729545, 185.87612903225806, 'X[2] <= 2.523\\nentropy = 0.33\\nsamples = 99\\nvalue = [93, 6]'),\n",
       " Text(136.59531310026892, 178.86193548387098, 'X[7] <= -1.995\\nentropy = 0.291\\nsamples = 98\\nvalue = [93, 5]'),\n",
       " Text(135.56634652324243, 171.84774193548387, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(137.62427967729545, 171.84774193548387, 'X[11] <= 5.683\\nentropy = 0.248\\nsamples = 97\\nvalue = [93, 4]'),\n",
       " Text(136.59531310026892, 164.83354838709678, 'X[8] <= -1.316\\nentropy = 0.201\\nsamples = 96\\nvalue = [93, 3]'),\n",
       " Text(135.56634652324243, 157.81935483870967, 'X[8] <= -1.363\\nentropy = 0.342\\nsamples = 47\\nvalue = [44, 3]'),\n",
       " Text(132.4794467921629, 150.8051612903226, 'X[7] <= 1.529\\nentropy = 0.162\\nsamples = 42\\nvalue = [41, 1]'),\n",
       " Text(131.4504802151364, 143.7909677419355, 'entropy = 0.0\\nsamples = 40\\nvalue = [40, 0]'),\n",
       " Text(133.5084133691894, 143.7909677419355, 'X[8] <= -1.641\\nentropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(132.4794467921629, 136.7767741935484, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(134.5373799462159, 136.7767741935484, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(138.65324625432194, 150.8051612903226, 'X[10] <= 0.351\\nentropy = 0.971\\nsamples = 5\\nvalue = [3, 2]'),\n",
       " Text(137.62427967729545, 143.7909677419355, 'X[7] <= -0.976\\nentropy = 0.918\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(136.59531310026892, 136.7767741935484, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(138.65324625432194, 136.7767741935484, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(139.68221283134847, 143.7909677419355, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(137.62427967729545, 157.81935483870967, 'entropy = 0.0\\nsamples = 49\\nvalue = [49, 0]'),\n",
       " Text(138.65324625432194, 164.83354838709678, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(138.65324625432194, 178.86193548387098, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(177.60877533134845, 185.87612903225806, 'X[0] <= 0.144\\nentropy = 0.634\\nsamples = 906\\nvalue = [761, 145]'),\n",
       " Text(158.9110257395313, 178.86193548387098, 'X[10] <= 1.1\\nentropy = 0.564\\nsamples = 491\\nvalue = [426, 65]'),\n",
       " Text(147.9139454475605, 171.84774193548387, 'X[9] <= 1.892\\nentropy = 0.513\\nsamples = 429\\nvalue = [380, 49]'),\n",
       " Text(145.8560122935075, 164.83354838709678, 'X[10] <= 0.726\\nentropy = 0.486\\nsamples = 417\\nvalue = [373, 44]'),\n",
       " Text(144.827045716481, 157.81935483870967, 'X[9] <= 1.14\\nentropy = 0.514\\nsamples = 383\\nvalue = [339, 44]'),\n",
       " Text(143.7980791394545, 150.8051612903226, 'X[3] <= 2.879\\nentropy = 0.535\\nsamples = 361\\nvalue = [317, 44]'),\n",
       " Text(141.74014598540148, 143.7909677419355, 'X[10] <= 0.642\\nentropy = 0.516\\nsamples = 355\\nvalue = [314, 41]'),\n",
       " Text(140.71117940837496, 136.7767741935484, 'X[10] <= -0.523\\nentropy = 0.509\\nsamples = 354\\nvalue = [314, 40]'),\n",
       " Text(125.66254321936228, 129.76258064516128, 'X[9] <= 0.998\\nentropy = 0.653\\nsamples = 113\\nvalue = [94, 19]'),\n",
       " Text(124.63357664233578, 122.7483870967742, 'X[8] <= -0.783\\nentropy = 0.618\\nsamples = 111\\nvalue = [94, 17]'),\n",
       " Text(123.60461006530927, 115.7341935483871, 'entropy = 0.0\\nsamples = 15\\nvalue = [15, 0]'),\n",
       " Text(125.66254321936228, 115.7341935483871, 'X[8] <= -0.69\\nentropy = 0.674\\nsamples = 96\\nvalue = [79, 17]'),\n",
       " Text(123.60461006530927, 108.72, 'X[2] <= -0.33\\nentropy = 0.971\\nsamples = 5\\nvalue = [2, 3]'),\n",
       " Text(122.57564348828276, 101.70580645161291, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(124.63357664233578, 101.70580645161291, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(127.7204763734153, 108.72, 'X[8] <= -0.458\\nentropy = 0.619\\nsamples = 91\\nvalue = [77, 14]'),\n",
       " Text(126.69150979638879, 101.70580645161291, 'entropy = 0.0\\nsamples = 17\\nvalue = [17, 0]'),\n",
       " Text(128.74944295044182, 101.70580645161291, 'X[1] <= 0.106\\nentropy = 0.7\\nsamples = 74\\nvalue = [60, 14]'),\n",
       " Text(127.7204763734153, 94.69161290322582, 'entropy = 0.0\\nsamples = 9\\nvalue = [9, 0]'),\n",
       " Text(129.7784095274683, 94.69161290322582, 'X[1] <= 0.456\\nentropy = 0.752\\nsamples = 65\\nvalue = [51, 14]'),\n",
       " Text(126.17702650787554, 87.67741935483872, 'X[11] <= -0.253\\nentropy = 0.989\\nsamples = 16\\nvalue = [9, 7]'),\n",
       " Text(125.14805993084903, 80.6632258064516, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(127.20599308490205, 80.6632258064516, 'X[2] <= -0.708\\nentropy = 0.89\\nsamples = 13\\nvalue = [9, 4]'),\n",
       " Text(126.17702650787554, 73.64903225806452, 'X[8] <= -0.168\\nentropy = 1.0\\nsamples = 8\\nvalue = [4, 4]'),\n",
       " Text(125.14805993084903, 66.63483870967744, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(127.20599308490205, 66.63483870967744, 'X[7] <= 1.049\\nentropy = 0.918\\nsamples = 6\\nvalue = [4, 2]'),\n",
       " Text(126.17702650787554, 59.62064516129033, 'X[8] <= -0.063\\nentropy = 0.722\\nsamples = 5\\nvalue = [4, 1]'),\n",
       " Text(125.14805993084903, 52.60645161290324, 'X[10] <= -1.023\\nentropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(124.11909335382252, 45.59225806451613, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(126.17702650787554, 45.59225806451613, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(127.20599308490205, 52.60645161290324, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(128.23495966192854, 59.62064516129033, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(128.23495966192854, 73.64903225806452, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
       " Text(133.3797925470611, 87.67741935483872, 'X[1] <= 1.272\\nentropy = 0.592\\nsamples = 49\\nvalue = [42, 7]'),\n",
       " Text(131.32185939300808, 80.6632258064516, 'X[8] <= -0.434\\nentropy = 0.33\\nsamples = 33\\nvalue = [31, 2]'),\n",
       " Text(130.29289281598156, 73.64903225806452, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(132.35082597003458, 73.64903225806452, 'X[7] <= -1.07\\nentropy = 0.201\\nsamples = 32\\nvalue = [31, 1]'),\n",
       " Text(131.32185939300808, 66.63483870967744, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(133.3797925470611, 66.63483870967744, 'entropy = 0.0\\nsamples = 31\\nvalue = [31, 0]'),\n",
       " Text(135.43772570111412, 80.6632258064516, 'X[9] <= -1.307\\nentropy = 0.896\\nsamples = 16\\nvalue = [11, 5]'),\n",
       " Text(134.4087591240876, 73.64903225806452, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(136.4666922781406, 73.64903225806452, 'X[8] <= -0.249\\nentropy = 0.75\\nsamples = 14\\nvalue = [11, 3]'),\n",
       " Text(135.43772570111412, 66.63483870967744, 'X[10] <= -0.857\\nentropy = 0.985\\nsamples = 7\\nvalue = [4, 3]'),\n",
       " Text(134.4087591240876, 59.62064516129033, 'X[1] <= 1.388\\nentropy = 0.722\\nsamples = 5\\nvalue = [4, 1]'),\n",
       " Text(133.3797925470611, 52.60645161290324, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(135.43772570111412, 52.60645161290324, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(136.4666922781406, 59.62064516129033, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(137.49565885516714, 66.63483870967744, 'entropy = 0.0\\nsamples = 7\\nvalue = [7, 0]'),\n",
       " Text(126.69150979638879, 122.7483870967742, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(155.75981559738764, 129.76258064516128, 'X[11] <= -0.672\\nentropy = 0.427\\nsamples = 241\\nvalue = [220, 21]'),\n",
       " Text(154.73084902036112, 122.7483870967742, 'entropy = 0.0\\nsamples = 34\\nvalue = [34, 0]'),\n",
       " Text(156.78878217441414, 122.7483870967742, 'X[11] <= 0.445\\nentropy = 0.474\\nsamples = 207\\nvalue = [186, 21]'),\n",
       " Text(149.32877449097197, 115.7341935483871, 'X[9] <= 0.418\\nentropy = 0.389\\nsamples = 157\\nvalue = [145, 12]'),\n",
       " Text(143.66945831732616, 108.72, 'X[2] <= -0.414\\nentropy = 0.303\\nsamples = 130\\nvalue = [123, 7]'),\n",
       " Text(140.58255858624665, 101.70580645161291, 'X[9] <= -0.214\\nentropy = 0.158\\nsamples = 87\\nvalue = [85, 2]'),\n",
       " Text(139.55359200922015, 94.69161290322582, 'entropy = 0.0\\nsamples = 47\\nvalue = [47, 0]'),\n",
       " Text(141.61152516327317, 94.69161290322582, 'X[7] <= 0.323\\nentropy = 0.286\\nsamples = 40\\nvalue = [38, 2]'),\n",
       " Text(140.58255858624665, 87.67741935483872, 'X[1] <= 0.281\\nentropy = 0.592\\nsamples = 14\\nvalue = [12, 2]'),\n",
       " Text(139.55359200922015, 80.6632258064516, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
       " Text(141.61152516327317, 80.6632258064516, 'X[7] <= 0.136\\nentropy = 0.764\\nsamples = 9\\nvalue = [7, 2]'),\n",
       " Text(140.58255858624665, 73.64903225806452, 'X[9] <= -0.19\\nentropy = 0.544\\nsamples = 8\\nvalue = [7, 1]'),\n",
       " Text(139.55359200922015, 66.63483870967744, 'X[1] <= 0.456\\nentropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(138.52462543219363, 59.62064516129033, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(140.58255858624665, 59.62064516129033, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(141.61152516327317, 66.63483870967744, 'entropy = 0.0\\nsamples = 6\\nvalue = [6, 0]'),\n",
       " Text(142.64049174029967, 73.64903225806452, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(142.64049174029967, 87.67741935483872, 'entropy = 0.0\\nsamples = 26\\nvalue = [26, 0]'),\n",
       " Text(146.7563580484057, 101.70580645161291, 'X[7] <= 0.206\\nentropy = 0.519\\nsamples = 43\\nvalue = [38, 5]'),\n",
       " Text(145.72739147137918, 94.69161290322582, 'entropy = 0.0\\nsamples = 23\\nvalue = [23, 0]'),\n",
       " Text(147.7853246254322, 94.69161290322582, 'X[5] <= 0.414\\nentropy = 0.811\\nsamples = 20\\nvalue = [15, 5]'),\n",
       " Text(146.7563580484057, 87.67741935483872, 'X[2] <= 1.348\\nentropy = 0.742\\nsamples = 19\\nvalue = [15, 4]'),\n",
       " Text(145.72739147137918, 80.6632258064516, 'X[2] <= 0.047\\nentropy = 0.65\\nsamples = 18\\nvalue = [15, 3]'),\n",
       " Text(144.69842489435268, 73.64903225806452, 'X[1] <= 0.572\\nentropy = 0.954\\nsamples = 8\\nvalue = [5, 3]'),\n",
       " Text(143.66945831732616, 66.63483870967744, 'X[9] <= -0.671\\nentropy = 0.971\\nsamples = 5\\nvalue = [2, 3]'),\n",
       " Text(142.64049174029967, 59.62064516129033, 'X[8] <= -0.864\\nentropy = 0.918\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(141.61152516327317, 52.60645161290324, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(143.66945831732616, 52.60645161290324, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(144.69842489435268, 59.62064516129033, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(145.72739147137918, 66.63483870967744, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(146.7563580484057, 73.64903225806452, 'entropy = 0.0\\nsamples = 10\\nvalue = [10, 0]'),\n",
       " Text(147.7853246254322, 80.6632258064516, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(148.81429120245872, 87.67741935483872, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(154.98809066461777, 108.72, 'X[9] <= 0.895\\nentropy = 0.691\\nsamples = 27\\nvalue = [22, 5]'),\n",
       " Text(153.95912408759125, 101.70580645161291, 'X[1] <= 1.213\\nentropy = 0.852\\nsamples = 18\\nvalue = [13, 5]'),\n",
       " Text(152.93015751056475, 94.69161290322582, 'X[7] <= -0.051\\nentropy = 0.94\\nsamples = 14\\nvalue = [9, 5]'),\n",
       " Text(150.87222435651174, 87.67741935483872, 'X[7] <= -0.344\\nentropy = 0.544\\nsamples = 8\\nvalue = [7, 1]'),\n",
       " Text(149.8432577794852, 80.6632258064516, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(151.90119093353823, 80.6632258064516, 'entropy = 0.0\\nsamples = 7\\nvalue = [7, 0]'),\n",
       " Text(154.98809066461777, 87.67741935483872, 'X[11] <= -0.218\\nentropy = 0.918\\nsamples = 6\\nvalue = [2, 4]'),\n",
       " Text(153.95912408759125, 80.6632258064516, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 4]'),\n",
       " Text(156.01705724164427, 80.6632258064516, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(154.98809066461777, 94.69161290322582, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(156.01705724164427, 101.70580645161291, 'entropy = 0.0\\nsamples = 9\\nvalue = [9, 0]'),\n",
       " Text(164.24878985785634, 115.7341935483871, 'X[8] <= -0.411\\nentropy = 0.68\\nsamples = 50\\nvalue = [41, 9]'),\n",
       " Text(162.19085670380332, 108.72, 'X[11] <= 1.283\\nentropy = 0.918\\nsamples = 18\\nvalue = [12, 6]'),\n",
       " Text(161.1618901267768, 101.70580645161291, 'X[9] <= -0.053\\nentropy = 0.996\\nsamples = 13\\nvalue = [7, 6]'),\n",
       " Text(160.1329235497503, 94.69161290322582, 'X[11] <= 1.178\\nentropy = 0.881\\nsamples = 10\\nvalue = [7, 3]'),\n",
       " Text(159.10395697272378, 87.67741935483872, 'X[11] <= 0.654\\nentropy = 0.764\\nsamples = 9\\nvalue = [7, 2]'),\n",
       " Text(158.07499039569728, 80.6632258064516, 'X[10] <= -0.399\\nentropy = 1.0\\nsamples = 4\\nvalue = [2, 2]'),\n",
       " Text(157.0460238186708, 73.64903225806452, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(159.10395697272378, 73.64903225806452, 'X[7] <= 0.101\\nentropy = 0.918\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(158.07499039569728, 66.63483870967744, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(160.1329235497503, 66.63483870967744, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(160.1329235497503, 80.6632258064516, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
       " Text(161.1618901267768, 87.67741935483872, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(162.19085670380332, 94.69161290322582, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(163.21982328082981, 101.70580645161291, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
       " Text(166.30672301190936, 108.72, 'X[11] <= 3.204\\nentropy = 0.449\\nsamples = 32\\nvalue = [29, 3]'),\n",
       " Text(165.27775643488283, 101.70580645161291, 'X[7] <= 1.096\\nentropy = 0.345\\nsamples = 31\\nvalue = [29, 2]'),\n",
       " Text(164.24878985785634, 94.69161290322582, 'entropy = 0.0\\nsamples = 24\\nvalue = [24, 0]'),\n",
       " Text(166.30672301190936, 94.69161290322582, 'X[9] <= -0.078\\nentropy = 0.863\\nsamples = 7\\nvalue = [5, 2]'),\n",
       " Text(165.27775643488283, 87.67741935483872, 'X[1] <= 1.505\\nentropy = 0.918\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(164.24878985785634, 80.6632258064516, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(166.30672301190936, 80.6632258064516, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(167.33568958893585, 87.67741935483872, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(167.33568958893585, 101.70580645161291, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(142.76911256242798, 136.7767741935484, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(145.8560122935075, 143.7909677419355, 'X[10] <= -0.69\\nentropy = 1.0\\nsamples = 6\\nvalue = [3, 3]'),\n",
       " Text(144.827045716481, 136.7767741935484, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(146.884978870534, 136.7767741935484, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(145.8560122935075, 150.8051612903226, 'entropy = 0.0\\nsamples = 22\\nvalue = [22, 0]'),\n",
       " Text(146.884978870534, 157.81935483870967, 'entropy = 0.0\\nsamples = 34\\nvalue = [34, 0]'),\n",
       " Text(149.97187860161353, 164.83354838709678, 'X[7] <= -0.133\\nentropy = 0.98\\nsamples = 12\\nvalue = [7, 5]'),\n",
       " Text(148.94291202458703, 157.81935483870967, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(151.00084517864005, 157.81935483870967, 'X[8] <= 0.262\\nentropy = 0.954\\nsamples = 8\\nvalue = [3, 5]'),\n",
       " Text(149.97187860161353, 150.8051612903226, 'X[8] <= -0.075\\nentropy = 0.811\\nsamples = 4\\nvalue = [3, 1]'),\n",
       " Text(148.94291202458703, 143.7909677419355, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(151.00084517864005, 143.7909677419355, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(152.02981175566654, 150.8051612903226, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 4]'),\n",
       " Text(169.90810603150211, 171.84774193548387, 'X[2] <= 0.299\\nentropy = 0.824\\nsamples = 62\\nvalue = [46, 16]'),\n",
       " Text(167.33568958893585, 164.83354838709678, 'X[9] <= -0.132\\nentropy = 0.684\\nsamples = 44\\nvalue = [36, 8]'),\n",
       " Text(165.27775643488283, 157.81935483870967, 'X[7] <= -0.965\\nentropy = 0.258\\nsamples = 23\\nvalue = [22, 1]'),\n",
       " Text(164.24878985785634, 150.8051612903226, 'X[8] <= 0.018\\nentropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(163.21982328082981, 143.7909677419355, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(165.27775643488283, 143.7909677419355, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(166.30672301190936, 150.8051612903226, 'entropy = 0.0\\nsamples = 21\\nvalue = [21, 0]'),\n",
       " Text(169.39362274298887, 157.81935483870967, 'X[9] <= 0.847\\nentropy = 0.918\\nsamples = 21\\nvalue = [14, 7]'),\n",
       " Text(168.36465616596237, 150.8051612903226, 'X[7] <= 1.342\\nentropy = 0.989\\nsamples = 16\\nvalue = [9, 7]'),\n",
       " Text(167.33568958893585, 143.7909677419355, 'X[7] <= -0.508\\nentropy = 0.996\\nsamples = 13\\nvalue = [6, 7]'),\n",
       " Text(166.30672301190936, 136.7767741935484, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(168.36465616596237, 136.7767741935484, 'X[8] <= 0.157\\nentropy = 0.994\\nsamples = 11\\nvalue = [6, 5]'),\n",
       " Text(167.33568958893585, 129.76258064516128, 'X[1] <= 0.514\\nentropy = 0.954\\nsamples = 8\\nvalue = [3, 5]'),\n",
       " Text(166.30672301190936, 122.7483870967742, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(168.36465616596237, 122.7483870967742, 'X[8] <= -0.434\\nentropy = 0.971\\nsamples = 5\\nvalue = [3, 2]'),\n",
       " Text(167.33568958893585, 115.7341935483871, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(169.39362274298887, 115.7341935483871, 'X[7] <= 0.265\\nentropy = 0.918\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(168.36465616596237, 108.72, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(170.4225893200154, 108.72, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(169.39362274298887, 129.76258064516128, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(169.39362274298887, 143.7909677419355, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(170.4225893200154, 150.8051612903226, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
       " Text(172.4805224740684, 164.83354838709678, 'X[9] <= -0.628\\nentropy = 0.991\\nsamples = 18\\nvalue = [10, 8]'),\n",
       " Text(171.45155589704189, 157.81935483870967, 'entropy = 0.0\\nsamples = 6\\nvalue = [0, 6]'),\n",
       " Text(173.5094890510949, 157.81935483870967, 'X[8] <= 0.296\\nentropy = 0.65\\nsamples = 12\\nvalue = [10, 2]'),\n",
       " Text(172.4805224740684, 150.8051612903226, 'entropy = 0.0\\nsamples = 10\\nvalue = [10, 0]'),\n",
       " Text(174.53845562812143, 150.8051612903226, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(196.3065249231656, 178.86193548387098, 'X[11] <= -1.161\\nentropy = 0.707\\nsamples = 415\\nvalue = [335, 80]'),\n",
       " Text(185.62396273530544, 171.84774193548387, 'X[1] <= 1.272\\nentropy = 0.196\\nsamples = 33\\nvalue = [32, 1]'),\n",
       " Text(184.59499615827892, 164.83354838709678, 'entropy = 0.0\\nsamples = 27\\nvalue = [27, 0]'),\n",
       " Text(186.65292931233193, 164.83354838709678, 'X[1] <= 1.388\\nentropy = 0.65\\nsamples = 6\\nvalue = [5, 1]'),\n",
       " Text(185.62396273530544, 157.81935483870967, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(187.68189588935846, 157.81935483870967, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
       " Text(206.98908711102575, 171.84774193548387, 'X[7] <= 2.348\\nentropy = 0.735\\nsamples = 382\\nvalue = [303, 79]'),\n",
       " Text(198.79553880138303, 164.83354838709678, 'X[10] <= -0.274\\nentropy = 0.722\\nsamples = 375\\nvalue = [300, 75]'),\n",
       " Text(189.73982904341148, 157.81935483870967, 'X[1] <= 0.106\\nentropy = 0.623\\nsamples = 193\\nvalue = [163, 30]'),\n",
       " Text(188.71086246638495, 150.8051612903226, 'entropy = 0.0\\nsamples = 15\\nvalue = [15, 0]'),\n",
       " Text(190.76879562043797, 150.8051612903226, 'X[11] <= 0.515\\nentropy = 0.654\\nsamples = 178\\nvalue = [148, 30]'),\n",
       " Text(184.10462927391472, 143.7909677419355, 'X[10] <= -1.398\\nentropy = 0.719\\nsamples = 141\\nvalue = [113, 28]'),\n",
       " Text(177.1108720706877, 136.7767741935484, 'X[9] <= -0.507\\nentropy = 0.918\\nsamples = 30\\nvalue = [20, 10]'),\n",
       " Text(176.08190549366117, 129.76258064516128, 'entropy = 0.0\\nsamples = 7\\nvalue = [7, 0]'),\n",
       " Text(178.13983864771419, 129.76258064516128, 'X[11] <= -0.079\\nentropy = 0.988\\nsamples = 23\\nvalue = [13, 10]'),\n",
       " Text(175.56742220514792, 122.7483870967742, 'X[9] <= 0.173\\nentropy = 0.989\\nsamples = 16\\nvalue = [7, 9]'),\n",
       " Text(173.5094890510949, 115.7341935483871, 'X[10] <= -1.773\\nentropy = 0.764\\nsamples = 9\\nvalue = [2, 7]'),\n",
       " Text(172.4805224740684, 108.72, 'X[9] <= -0.268\\nentropy = 1.0\\nsamples = 4\\nvalue = [2, 2]'),\n",
       " Text(171.45155589704189, 101.70580645161291, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(173.5094890510949, 101.70580645161291, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(174.53845562812143, 108.72, 'entropy = 0.0\\nsamples = 5\\nvalue = [0, 5]'),\n",
       " Text(177.62535535920094, 115.7341935483871, 'X[7] <= -0.883\\nentropy = 0.863\\nsamples = 7\\nvalue = [5, 2]'),\n",
       " Text(176.59638878217442, 108.72, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(178.65432193622743, 108.72, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
       " Text(180.71225509028045, 122.7483870967742, 'X[1] <= 1.33\\nentropy = 0.592\\nsamples = 7\\nvalue = [6, 1]'),\n",
       " Text(179.68328851325396, 115.7341935483871, 'entropy = 0.0\\nsamples = 6\\nvalue = [6, 0]'),\n",
       " Text(181.74122166730697, 115.7341935483871, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(191.0983864771418, 136.7767741935484, 'X[9] <= 0.747\\nentropy = 0.639\\nsamples = 111\\nvalue = [93, 18]'),\n",
       " Text(188.87967729542837, 129.76258064516128, 'X[9] <= 0.181\\nentropy = 0.555\\nsamples = 93\\nvalue = [81, 12]'),\n",
       " Text(187.85071071840187, 122.7483870967742, 'X[11] <= 0.235\\nentropy = 0.667\\nsamples = 69\\nvalue = [57, 12]'),\n",
       " Text(184.44225893200155, 115.7341935483871, 'X[9] <= 0.157\\nentropy = 0.586\\nsamples = 64\\nvalue = [55, 9]'),\n",
       " Text(180.71225509028045, 108.72, 'X[2] <= -0.414\\nentropy = 0.514\\nsamples = 61\\nvalue = [54, 7]'),\n",
       " Text(176.3391471379178, 101.70580645161291, 'X[7] <= 0.452\\nentropy = 0.235\\nsamples = 26\\nvalue = [25, 1]'),\n",
       " Text(175.3101805608913, 94.69161290322582, 'entropy = 0.0\\nsamples = 19\\nvalue = [19, 0]'),\n",
       " Text(177.36811371494431, 94.69161290322582, 'X[7] <= 0.487\\nentropy = 0.592\\nsamples = 7\\nvalue = [6, 1]'),\n",
       " Text(176.3391471379178, 87.67741935483872, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(178.3970802919708, 87.67741935483872, 'entropy = 0.0\\nsamples = 6\\nvalue = [6, 0]'),\n",
       " Text(185.0853630426431, 101.70580645161291, 'X[7] <= -0.262\\nentropy = 0.661\\nsamples = 35\\nvalue = [29, 6]'),\n",
       " Text(182.51294660007684, 94.69161290322582, 'X[7] <= -0.485\\nentropy = 0.874\\nsamples = 17\\nvalue = [12, 5]'),\n",
       " Text(180.45501344602383, 87.67741935483872, 'X[2] <= 0.089\\nentropy = 0.414\\nsamples = 12\\nvalue = [11, 1]'),\n",
       " Text(179.42604686899733, 80.6632258064516, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(181.48398002305035, 80.6632258064516, 'entropy = 0.0\\nsamples = 11\\nvalue = [11, 0]'),\n",
       " Text(184.57087975412986, 87.67741935483872, 'X[8] <= -0.005\\nentropy = 0.722\\nsamples = 5\\nvalue = [1, 4]'),\n",
       " Text(183.54191317710337, 80.6632258064516, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 4]'),\n",
       " Text(185.59984633115639, 80.6632258064516, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(187.65777948520937, 94.69161290322582, 'X[9] <= -0.22\\nentropy = 0.31\\nsamples = 18\\nvalue = [17, 1]'),\n",
       " Text(186.62881290818288, 87.67741935483872, 'entropy = 0.0\\nsamples = 14\\nvalue = [14, 0]'),\n",
       " Text(188.6867460622359, 87.67741935483872, 'X[10] <= -0.69\\nentropy = 0.811\\nsamples = 4\\nvalue = [3, 1]'),\n",
       " Text(187.65777948520937, 80.6632258064516, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(189.7157126392624, 80.6632258064516, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(188.17226277372265, 108.72, 'X[1] <= 1.738\\nentropy = 0.918\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(187.14329619669613, 101.70580645161291, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(189.20122935074914, 101.70580645161291, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(191.25916250480216, 115.7341935483871, 'X[8] <= -0.493\\nentropy = 0.971\\nsamples = 5\\nvalue = [2, 3]'),\n",
       " Text(190.23019592777567, 108.72, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(192.28812908182869, 108.72, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(189.9086438724549, 122.7483870967742, 'entropy = 0.0\\nsamples = 24\\nvalue = [24, 0]'),\n",
       " Text(193.31709565885518, 129.76258064516128, 'X[8] <= -0.272\\nentropy = 0.918\\nsamples = 18\\nvalue = [12, 6]'),\n",
       " Text(192.28812908182869, 122.7483870967742, 'entropy = 0.0\\nsamples = 6\\nvalue = [6, 0]'),\n",
       " Text(194.3460622358817, 122.7483870967742, 'X[7] <= -0.941\\nentropy = 1.0\\nsamples = 12\\nvalue = [6, 6]'),\n",
       " Text(193.31709565885518, 115.7341935483871, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(195.3750288129082, 115.7341935483871, 'X[8] <= 0.169\\nentropy = 0.918\\nsamples = 9\\nvalue = [3, 6]'),\n",
       " Text(194.3460622358817, 108.72, 'X[11] <= -0.393\\nentropy = 1.0\\nsamples = 6\\nvalue = [3, 3]'),\n",
       " Text(193.31709565885518, 101.70580645161291, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(195.3750288129082, 101.70580645161291, 'X[7] <= -0.684\\nentropy = 0.811\\nsamples = 4\\nvalue = [3, 1]'),\n",
       " Text(194.3460622358817, 94.69161290322582, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(196.4039953899347, 94.69161290322582, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(196.4039953899347, 108.72, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(197.43296196696122, 143.7909677419355, 'X[2] <= 2.187\\nentropy = 0.303\\nsamples = 37\\nvalue = [35, 2]'),\n",
       " Text(196.4039953899347, 136.7767741935484, 'X[7] <= 1.412\\nentropy = 0.183\\nsamples = 36\\nvalue = [35, 1]'),\n",
       " Text(195.3750288129082, 129.76258064516128, 'entropy = 0.0\\nsamples = 33\\nvalue = [33, 0]'),\n",
       " Text(197.43296196696122, 129.76258064516128, 'X[1] <= 1.213\\nentropy = 0.918\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(196.4039953899347, 122.7483870967742, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(198.4619285439877, 122.7483870967742, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(198.4619285439877, 136.7767741935484, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(207.85124855935462, 157.81935483870967, 'X[11] <= -0.952\\nentropy = 0.807\\nsamples = 182\\nvalue = [137, 45]'),\n",
       " Text(202.57779485209375, 150.8051612903226, 'X[9] <= 0.132\\nentropy = 0.954\\nsamples = 8\\nvalue = [3, 5]'),\n",
       " Text(201.54882827506725, 143.7909677419355, 'X[7] <= -0.508\\nentropy = 0.971\\nsamples = 5\\nvalue = [3, 2]'),\n",
       " Text(200.51986169804073, 136.7767741935484, 'X[7] <= -1.0\\nentropy = 0.918\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(199.49089512101423, 129.76258064516128, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(201.54882827506725, 129.76258064516128, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(202.57779485209375, 136.7767741935484, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(203.60676142912027, 143.7909677419355, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(213.12470226661546, 150.8051612903226, 'X[1] <= 0.456\\nentropy = 0.778\\nsamples = 174\\nvalue = [134, 40]'),\n",
       " Text(207.20814444871303, 143.7909677419355, 'X[9] <= 0.554\\nentropy = 0.897\\nsamples = 67\\nvalue = [46, 21]'),\n",
       " Text(204.63572800614676, 136.7767741935484, 'X[11] <= 1.213\\nentropy = 0.738\\nsamples = 48\\nvalue = [38, 10]'),\n",
       " Text(203.60676142912027, 129.76258064516128, 'X[8] <= 0.053\\nentropy = 0.624\\nsamples = 45\\nvalue = [38, 7]'),\n",
       " Text(202.57779485209375, 122.7483870967742, 'X[1] <= -0.011\\nentropy = 0.746\\nsamples = 33\\nvalue = [26, 7]'),\n",
       " Text(201.54882827506725, 115.7341935483871, 'entropy = 0.0\\nsamples = 7\\nvalue = [7, 0]'),\n",
       " Text(203.60676142912027, 115.7341935483871, 'X[2] <= 1.348\\nentropy = 0.84\\nsamples = 26\\nvalue = [19, 7]'),\n",
       " Text(202.57779485209375, 108.72, 'X[9] <= 0.208\\nentropy = 0.918\\nsamples = 21\\nvalue = [14, 7]'),\n",
       " Text(201.54882827506725, 101.70580645161291, 'X[7] <= -0.449\\nentropy = 0.831\\nsamples = 19\\nvalue = [14, 5]'),\n",
       " Text(200.51986169804073, 94.69161290322582, 'entropy = 0.0\\nsamples = 6\\nvalue = [6, 0]'),\n",
       " Text(202.57779485209375, 94.69161290322582, 'X[11] <= 0.061\\nentropy = 0.961\\nsamples = 13\\nvalue = [8, 5]'),\n",
       " Text(201.54882827506725, 87.67741935483872, 'X[9] <= -0.466\\nentropy = 0.845\\nsamples = 11\\nvalue = [8, 3]'),\n",
       " Text(200.51986169804073, 80.6632258064516, 'X[10] <= 0.143\\nentropy = 1.0\\nsamples = 6\\nvalue = [3, 3]'),\n",
       " Text(199.49089512101423, 73.64903225806452, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(201.54882827506725, 73.64903225806452, 'X[11] <= -0.533\\nentropy = 0.811\\nsamples = 4\\nvalue = [3, 1]'),\n",
       " Text(200.51986169804073, 66.63483870967744, 'X[7] <= 0.557\\nentropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(199.49089512101423, 59.62064516129033, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(201.54882827506725, 59.62064516129033, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(202.57779485209375, 66.63483870967744, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(202.57779485209375, 80.6632258064516, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
       " Text(203.60676142912027, 87.67741935483872, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(203.60676142912027, 101.70580645161291, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(204.63572800614676, 108.72, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
       " Text(204.63572800614676, 122.7483870967742, 'entropy = 0.0\\nsamples = 12\\nvalue = [12, 0]'),\n",
       " Text(205.6646945831733, 129.76258064516128, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(209.78056089127932, 136.7767741935484, 'X[10] <= 0.892\\nentropy = 0.982\\nsamples = 19\\nvalue = [8, 11]'),\n",
       " Text(207.7226277372263, 129.76258064516128, 'X[9] <= 2.052\\nentropy = 0.65\\nsamples = 12\\nvalue = [2, 10]'),\n",
       " Text(206.69366116019978, 122.7483870967742, 'X[8] <= 0.25\\nentropy = 0.439\\nsamples = 11\\nvalue = [1, 10]'),\n",
       " Text(205.6646945831733, 115.7341935483871, 'entropy = 0.0\\nsamples = 9\\nvalue = [0, 9]'),\n",
       " Text(207.7226277372263, 115.7341935483871, 'X[8] <= 0.343\\nentropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(206.69366116019978, 108.72, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(208.7515943142528, 108.72, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(208.7515943142528, 122.7483870967742, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(211.83849404533234, 129.76258064516128, 'X[11] <= -0.393\\nentropy = 0.592\\nsamples = 7\\nvalue = [6, 1]'),\n",
       " Text(210.80952746830582, 122.7483870967742, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(212.86746062235883, 122.7483870967742, 'entropy = 0.0\\nsamples = 6\\nvalue = [6, 0]'),\n",
       " Text(219.0412600845179, 143.7909677419355, 'X[9] <= -0.492\\nentropy = 0.675\\nsamples = 107\\nvalue = [88, 19]'),\n",
       " Text(216.98332693046487, 136.7767741935484, 'X[9] <= -0.539\\nentropy = 0.894\\nsamples = 29\\nvalue = [20, 9]'),\n",
       " Text(215.95436035343835, 129.76258064516128, 'X[8] <= 0.169\\nentropy = 0.826\\nsamples = 27\\nvalue = [20, 7]'),\n",
       " Text(214.92539377641185, 122.7483870967742, 'X[9] <= -1.068\\nentropy = 0.902\\nsamples = 22\\nvalue = [15, 7]'),\n",
       " Text(212.86746062235883, 115.7341935483871, 'X[2] <= 0.719\\nentropy = 0.985\\nsamples = 7\\nvalue = [3, 4]'),\n",
       " Text(211.83849404533234, 108.72, 'X[8] <= -0.539\\nentropy = 0.971\\nsamples = 5\\nvalue = [3, 2]'),\n",
       " Text(210.80952746830582, 101.70580645161291, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(212.86746062235883, 101.70580645161291, 'X[10] <= 0.268\\nentropy = 0.918\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(211.83849404533234, 94.69161290322582, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(213.89642719938533, 94.69161290322582, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(213.89642719938533, 108.72, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(216.98332693046487, 115.7341935483871, 'X[2] <= 2.187\\nentropy = 0.722\\nsamples = 15\\nvalue = [12, 3]'),\n",
       " Text(215.95436035343835, 108.72, 'X[1] <= 1.505\\nentropy = 0.592\\nsamples = 14\\nvalue = [12, 2]'),\n",
       " Text(214.92539377641185, 101.70580645161291, 'entropy = 0.0\\nsamples = 9\\nvalue = [9, 0]'),\n",
       " Text(216.98332693046487, 101.70580645161291, 'X[11] <= 0.235\\nentropy = 0.971\\nsamples = 5\\nvalue = [3, 2]'),\n",
       " Text(215.95436035343835, 94.69161290322582, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(218.01229350749136, 94.69161290322582, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(218.01229350749136, 108.72, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(216.98332693046487, 122.7483870967742, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
       " Text(218.01229350749136, 129.76258064516128, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(221.0991932385709, 136.7767741935484, 'X[11] <= 4.007\\nentropy = 0.552\\nsamples = 78\\nvalue = [68, 10]'),\n",
       " Text(220.07022666154438, 129.76258064516128, 'X[7] <= -1.807\\nentropy = 0.52\\nsamples = 77\\nvalue = [68, 9]'),\n",
       " Text(219.0412600845179, 122.7483870967742, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(221.0991932385709, 122.7483870967742, 'X[7] <= -0.871\\nentropy = 0.485\\nsamples = 76\\nvalue = [68, 8]'),\n",
       " Text(220.07022666154438, 115.7341935483871, 'entropy = 0.0\\nsamples = 14\\nvalue = [14, 0]'),\n",
       " Text(222.1281598155974, 115.7341935483871, 'X[7] <= -0.836\\nentropy = 0.555\\nsamples = 62\\nvalue = [54, 8]'),\n",
       " Text(221.0991932385709, 108.72, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(223.15712639262392, 108.72, 'X[11] <= -0.253\\nentropy = 0.514\\nsamples = 61\\nvalue = [54, 7]'),\n",
       " Text(222.1281598155974, 101.70580645161291, 'entropy = 0.0\\nsamples = 19\\nvalue = [19, 0]'),\n",
       " Text(224.18609296965042, 101.70580645161291, 'X[11] <= -0.184\\nentropy = 0.65\\nsamples = 42\\nvalue = [35, 7]'),\n",
       " Text(223.15712639262392, 94.69161290322582, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(225.21505954667694, 94.69161290322582, 'X[8] <= 0.389\\nentropy = 0.601\\nsamples = 41\\nvalue = [35, 6]'),\n",
       " Text(223.15712639262392, 87.67741935483872, 'X[2] <= 0.719\\nentropy = 0.494\\nsamples = 37\\nvalue = [33, 4]'),\n",
       " Text(222.1281598155974, 80.6632258064516, 'X[2] <= 0.131\\nentropy = 0.605\\nsamples = 27\\nvalue = [23, 4]'),\n",
       " Text(221.0991932385709, 73.64903225806452, 'X[1] <= 1.155\\nentropy = 0.516\\nsamples = 26\\nvalue = [23, 3]'),\n",
       " Text(220.07022666154438, 66.63483870967744, 'X[7] <= 0.616\\nentropy = 0.722\\nsamples = 15\\nvalue = [12, 3]'),\n",
       " Text(218.01229350749136, 59.62064516129033, 'X[1] <= 1.038\\nentropy = 0.414\\nsamples = 12\\nvalue = [11, 1]'),\n",
       " Text(216.98332693046487, 52.60645161290324, 'entropy = 0.0\\nsamples = 11\\nvalue = [11, 0]'),\n",
       " Text(219.0412600845179, 52.60645161290324, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(222.1281598155974, 59.62064516129033, 'X[8] <= 0.296\\nentropy = 0.918\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(221.0991932385709, 52.60645161290324, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(223.15712639262392, 52.60645161290324, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(222.1281598155974, 66.63483870967744, 'entropy = 0.0\\nsamples = 11\\nvalue = [11, 0]'),\n",
       " Text(223.15712639262392, 73.64903225806452, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(224.18609296965042, 80.6632258064516, 'entropy = 0.0\\nsamples = 10\\nvalue = [10, 0]'),\n",
       " Text(227.27299270072996, 87.67741935483872, 'X[7] <= -0.368\\nentropy = 1.0\\nsamples = 4\\nvalue = [2, 2]'),\n",
       " Text(226.24402612370343, 80.6632258064516, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(228.30195927775645, 80.6632258064516, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(222.1281598155974, 129.76258064516128, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(215.18263542066848, 164.83354838709678, 'X[10] <= -0.065\\nentropy = 0.985\\nsamples = 7\\nvalue = [3, 4]'),\n",
       " Text(214.15366884364198, 157.81935483870967, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(216.21160199769497, 157.81935483870967, 'X[7] <= 2.407\\nentropy = 0.811\\nsamples = 4\\nvalue = [3, 1]'),\n",
       " Text(215.18263542066848, 150.8051612903226, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(217.2405685747215, 150.8051612903226, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(224.70057625816366, 192.89032258064515, 'X[10] <= -1.19\\nentropy = 0.952\\nsamples = 35\\nvalue = [22, 13]'),\n",
       " Text(223.67160968113717, 185.87612903225806, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
       " Text(225.7295428351902, 185.87612903225806, 'X[2] <= 0.047\\nentropy = 0.987\\nsamples = 30\\nvalue = [17, 13]'),\n",
       " Text(224.70057625816366, 178.86193548387098, 'X[11] <= -1.161\\nentropy = 0.999\\nsamples = 27\\nvalue = [14, 13]'),\n",
       " Text(223.67160968113717, 171.84774193548387, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(225.7295428351902, 171.84774193548387, 'X[10] <= -0.399\\nentropy = 0.99\\nsamples = 25\\nvalue = [14, 11]'),\n",
       " Text(223.15712639262392, 164.83354838709678, 'X[7] <= 0.124\\nentropy = 0.971\\nsamples = 15\\nvalue = [6, 9]'),\n",
       " Text(221.0991932385709, 157.81935483870967, 'X[9] <= -0.77\\nentropy = 0.863\\nsamples = 7\\nvalue = [5, 2]'),\n",
       " Text(220.07022666154438, 150.8051612903226, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(222.1281598155974, 150.8051612903226, 'X[9] <= 1.082\\nentropy = 0.65\\nsamples = 6\\nvalue = [5, 1]'),\n",
       " Text(221.0991932385709, 143.7909677419355, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
       " Text(223.15712639262392, 143.7909677419355, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(225.21505954667694, 157.81935483870967, 'X[11] <= 1.318\\nentropy = 0.544\\nsamples = 8\\nvalue = [1, 7]'),\n",
       " Text(224.18609296965042, 150.8051612903226, 'entropy = 0.0\\nsamples = 7\\nvalue = [0, 7]'),\n",
       " Text(226.24402612370343, 150.8051612903226, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(228.30195927775645, 164.83354838709678, 'X[5] <= 0.414\\nentropy = 0.722\\nsamples = 10\\nvalue = [8, 2]'),\n",
       " Text(227.27299270072996, 157.81935483870967, 'entropy = 0.0\\nsamples = 7\\nvalue = [7, 0]'),\n",
       " Text(229.33092585478295, 157.81935483870967, 'X[1] <= 2.088\\nentropy = 0.918\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(228.30195927775645, 150.8051612903226, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(230.35989243180947, 150.8051612903226, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(226.75850941221668, 178.86193548387098, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(301.22192662312716, 199.90451612903226, 'X[2] <= 0.299\\nentropy = 0.884\\nsamples = 661\\nvalue = [461, 200]'),\n",
       " Text(277.4190357280062, 192.89032258064515, 'X[8] <= 1.84\\nentropy = 0.825\\nsamples = 522\\nvalue = [387, 135]'),\n",
       " Text(256.82362658471, 185.87612903225806, 'X[7] <= 0.112\\nentropy = 0.763\\nsamples = 393\\nvalue = [306, 87]'),\n",
       " Text(244.95835574337306, 178.86193548387098, 'X[4] <= 6.593\\nentropy = 0.876\\nsamples = 179\\nvalue = [126, 53]'),\n",
       " Text(243.92938916634654, 171.84774193548387, 'X[10] <= -1.523\\nentropy = 0.861\\nsamples = 176\\nvalue = [126, 50]'),\n",
       " Text(242.90042258932004, 164.83354838709678, 'entropy = 0.0\\nsamples = 10\\nvalue = [10, 0]'),\n",
       " Text(244.95835574337306, 164.83354838709678, 'X[1] <= 1.155\\nentropy = 0.883\\nsamples = 166\\nvalue = [116, 50]'),\n",
       " Text(235.3761044948137, 157.81935483870967, 'X[10] <= -1.231\\nentropy = 0.777\\nsamples = 96\\nvalue = [74, 22]'),\n",
       " Text(232.4178255858625, 150.8051612903226, 'X[8] <= 1.086\\nentropy = 0.985\\nsamples = 7\\nvalue = [3, 4]'),\n",
       " Text(231.38885900883596, 143.7909677419355, 'X[9] <= 2.021\\nentropy = 0.811\\nsamples = 4\\nvalue = [3, 1]'),\n",
       " Text(230.35989243180947, 136.7767741935484, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(232.4178255858625, 136.7767741935484, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(233.44679216288898, 143.7909677419355, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(238.33438340376492, 150.8051612903226, 'X[9] <= 1.988\\nentropy = 0.726\\nsamples = 89\\nvalue = [71, 18]'),\n",
       " Text(237.3054168267384, 143.7909677419355, 'X[7] <= -0.133\\nentropy = 0.769\\nsamples = 80\\nvalue = [62, 18]'),\n",
       " Text(234.4757587399155, 136.7767741935484, 'X[11] <= 0.794\\nentropy = 0.643\\nsamples = 55\\nvalue = [46, 9]'),\n",
       " Text(233.44679216288898, 129.76258064516128, 'X[1] <= 0.397\\nentropy = 0.769\\nsamples = 40\\nvalue = [31, 9]'),\n",
       " Text(229.84540914329622, 122.7483870967742, 'X[8] <= 1.561\\nentropy = 0.31\\nsamples = 18\\nvalue = [17, 1]'),\n",
       " Text(228.8164425662697, 115.7341935483871, 'entropy = 0.0\\nsamples = 16\\nvalue = [16, 0]'),\n",
       " Text(230.87437572032272, 115.7341935483871, 'X[8] <= 1.654\\nentropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(229.84540914329622, 108.72, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(231.90334229734924, 108.72, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(237.04817518248177, 122.7483870967742, 'X[7] <= -0.332\\nentropy = 0.946\\nsamples = 22\\nvalue = [14, 8]'),\n",
       " Text(236.01920860545528, 115.7341935483871, 'X[10] <= 0.143\\nentropy = 0.998\\nsamples = 17\\nvalue = [9, 8]'),\n",
       " Text(233.96127545140226, 108.72, 'X[9] <= 0.659\\nentropy = 0.764\\nsamples = 9\\nvalue = [2, 7]'),\n",
       " Text(232.93230887437574, 101.70580645161291, 'entropy = 0.0\\nsamples = 6\\nvalue = [0, 6]'),\n",
       " Text(234.99024202842875, 101.70580645161291, 'X[7] <= -0.473\\nentropy = 0.918\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(233.96127545140226, 94.69161290322582, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(236.01920860545528, 94.69161290322582, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(238.07714175950827, 108.72, 'X[9] <= -0.875\\nentropy = 0.544\\nsamples = 8\\nvalue = [7, 1]'),\n",
       " Text(237.04817518248177, 101.70580645161291, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(239.1061083365348, 101.70580645161291, 'entropy = 0.0\\nsamples = 7\\nvalue = [7, 0]'),\n",
       " Text(238.07714175950827, 115.7341935483871, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
       " Text(235.504725316942, 129.76258064516128, 'entropy = 0.0\\nsamples = 15\\nvalue = [15, 0]'),\n",
       " Text(240.13507491356128, 136.7767741935484, 'X[10] <= -0.565\\nentropy = 0.943\\nsamples = 25\\nvalue = [16, 9]'),\n",
       " Text(239.1061083365348, 129.76258064516128, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
       " Text(241.1640414905878, 129.76258064516128, 'X[9] <= -0.303\\nentropy = 0.993\\nsamples = 20\\nvalue = [11, 9]'),\n",
       " Text(240.13507491356128, 122.7483870967742, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(242.1930080676143, 122.7483870967742, 'X[10] <= -0.44\\nentropy = 0.964\\nsamples = 18\\nvalue = [11, 7]'),\n",
       " Text(241.1640414905878, 115.7341935483871, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(243.22197464464082, 115.7341935483871, 'X[9] <= 1.538\\nentropy = 0.896\\nsamples = 16\\nvalue = [11, 5]'),\n",
       " Text(242.1930080676143, 108.72, 'X[9] <= 0.339\\nentropy = 0.75\\nsamples = 14\\nvalue = [11, 3]'),\n",
       " Text(241.1640414905878, 101.70580645161291, 'X[10] <= -0.19\\nentropy = 0.954\\nsamples = 8\\nvalue = [5, 3]'),\n",
       " Text(240.13507491356128, 94.69161290322582, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(242.1930080676143, 94.69161290322582, 'X[9] <= -0.044\\nentropy = 1.0\\nsamples = 6\\nvalue = [3, 3]'),\n",
       " Text(241.1640414905878, 87.67741935483872, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(243.22197464464082, 87.67741935483872, 'X[11] <= 0.061\\nentropy = 0.811\\nsamples = 4\\nvalue = [1, 3]'),\n",
       " Text(242.1930080676143, 80.6632258064516, 'X[10] <= 1.433\\nentropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(241.1640414905878, 73.64903225806452, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(243.22197464464082, 73.64903225806452, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(244.25094122166732, 80.6632258064516, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(243.22197464464082, 101.70580645161291, 'entropy = 0.0\\nsamples = 6\\nvalue = [6, 0]'),\n",
       " Text(244.25094122166732, 108.72, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(239.3633499807914, 143.7909677419355, 'entropy = 0.0\\nsamples = 9\\nvalue = [9, 0]'),\n",
       " Text(254.5406069919324, 157.81935483870967, 'X[7] <= -1.21\\nentropy = 0.971\\nsamples = 70\\nvalue = [42, 28]'),\n",
       " Text(252.4826738378794, 150.8051612903226, 'X[9] <= 2.428\\nentropy = 0.881\\nsamples = 10\\nvalue = [3, 7]'),\n",
       " Text(251.4537072608529, 143.7909677419355, 'X[8] <= 1.724\\nentropy = 0.544\\nsamples = 8\\nvalue = [1, 7]'),\n",
       " Text(250.42474068382637, 136.7767741935484, 'entropy = 0.0\\nsamples = 7\\nvalue = [0, 7]'),\n",
       " Text(252.4826738378794, 136.7767741935484, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(253.51164041490588, 143.7909677419355, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(256.5985401459854, 150.8051612903226, 'X[7] <= -0.894\\nentropy = 0.934\\nsamples = 60\\nvalue = [39, 21]'),\n",
       " Text(255.5695735689589, 143.7909677419355, 'entropy = 0.0\\nsamples = 9\\nvalue = [9, 0]'),\n",
       " Text(257.62750672301195, 143.7909677419355, 'X[1] <= 2.088\\nentropy = 0.977\\nsamples = 51\\nvalue = [30, 21]'),\n",
       " Text(256.5985401459854, 136.7767741935484, 'X[3] <= 2.879\\nentropy = 0.992\\nsamples = 47\\nvalue = [26, 21]'),\n",
       " Text(255.5695735689589, 129.76258064516128, 'X[10] <= 1.475\\nentropy = 0.982\\nsamples = 45\\nvalue = [26, 19]'),\n",
       " Text(254.5406069919324, 122.7483870967742, 'X[2] <= -0.12\\nentropy = 0.968\\nsamples = 43\\nvalue = [26, 17]'),\n",
       " Text(253.51164041490588, 115.7341935483871, 'X[1] <= 1.854\\nentropy = 0.984\\nsamples = 40\\nvalue = [23, 17]'),\n",
       " Text(252.4826738378794, 108.72, 'X[10] <= -1.106\\nentropy = 0.992\\nsamples = 38\\nvalue = [21, 17]'),\n",
       " Text(251.4537072608529, 101.70580645161291, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(253.51164041490588, 101.70580645161291, 'X[11] <= 0.166\\nentropy = 0.998\\nsamples = 36\\nvalue = [19, 17]'),\n",
       " Text(250.42474068382637, 94.69161290322582, 'X[10] <= -0.19\\nentropy = 0.946\\nsamples = 22\\nvalue = [14, 8]'),\n",
       " Text(247.33784095274686, 87.67741935483872, 'X[8] <= 0.61\\nentropy = 0.994\\nsamples = 11\\nvalue = [5, 6]'),\n",
       " Text(246.30887437572034, 80.6632258064516, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(248.36680752977335, 80.6632258064516, 'X[7] <= -0.613\\nentropy = 0.592\\nsamples = 7\\nvalue = [1, 6]'),\n",
       " Text(247.33784095274686, 73.64903225806452, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(249.39577410679988, 73.64903225806452, 'entropy = 0.0\\nsamples = 6\\nvalue = [0, 6]'),\n",
       " Text(253.51164041490588, 87.67741935483872, 'X[8] <= 0.761\\nentropy = 0.684\\nsamples = 11\\nvalue = [9, 2]'),\n",
       " Text(252.4826738378794, 80.6632258064516, 'X[10] <= 0.851\\nentropy = 0.918\\nsamples = 6\\nvalue = [4, 2]'),\n",
       " Text(251.4537072608529, 73.64903225806452, 'X[7] <= -0.567\\nentropy = 0.722\\nsamples = 5\\nvalue = [4, 1]'),\n",
       " Text(250.42474068382637, 66.63483870967744, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(252.4826738378794, 66.63483870967744, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(253.51164041490588, 73.64903225806452, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(254.5406069919324, 80.6632258064516, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
       " Text(256.5985401459854, 94.69161290322582, 'X[7] <= -0.262\\nentropy = 0.94\\nsamples = 14\\nvalue = [5, 9]'),\n",
       " Text(255.5695735689589, 87.67741935483872, 'entropy = 0.0\\nsamples = 6\\nvalue = [0, 6]'),\n",
       " Text(257.62750672301195, 87.67741935483872, 'X[10] <= 0.559\\nentropy = 0.954\\nsamples = 8\\nvalue = [5, 3]'),\n",
       " Text(256.5985401459854, 80.6632258064516, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(258.65647330003844, 80.6632258064516, 'X[1] <= 1.388\\nentropy = 0.971\\nsamples = 5\\nvalue = [2, 3]'),\n",
       " Text(257.62750672301195, 73.64903225806452, 'X[8] <= 1.155\\nentropy = 0.918\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(256.5985401459854, 66.63483870967744, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(258.65647330003844, 66.63483870967744, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(259.68543987706494, 73.64903225806452, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(254.5406069919324, 108.72, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(255.5695735689589, 115.7341935483871, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(256.5985401459854, 122.7483870967742, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(257.62750672301195, 129.76258064516128, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(258.65647330003844, 136.7767741935484, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(245.98732232039956, 171.84774193548387, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(268.6888974260469, 178.86193548387098, 'X[1] <= 0.805\\nentropy = 0.632\\nsamples = 214\\nvalue = [180, 34]'),\n",
       " Text(263.801306185171, 171.84774193548387, 'X[7] <= 0.698\\nentropy = 0.401\\nsamples = 88\\nvalue = [81, 7]'),\n",
       " Text(262.7723396081445, 164.83354838709678, 'entropy = 0.0\\nsamples = 33\\nvalue = [33, 0]'),\n",
       " Text(264.83027276219747, 164.83354838709678, 'X[0] <= 0.144\\nentropy = 0.55\\nsamples = 55\\nvalue = [48, 7]'),\n",
       " Text(261.743373031118, 157.81935483870967, 'X[11] <= -0.323\\nentropy = 0.348\\nsamples = 46\\nvalue = [43, 3]'),\n",
       " Text(260.71440645409143, 150.8051612903226, 'X[11] <= -0.603\\nentropy = 0.696\\nsamples = 16\\nvalue = [13, 3]'),\n",
       " Text(259.68543987706494, 143.7909677419355, 'entropy = 0.0\\nsamples = 9\\nvalue = [9, 0]'),\n",
       " Text(261.743373031118, 143.7909677419355, 'X[1] <= 0.339\\nentropy = 0.985\\nsamples = 7\\nvalue = [4, 3]'),\n",
       " Text(260.71440645409143, 136.7767741935484, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(262.7723396081445, 136.7767741935484, 'X[8] <= 1.178\\nentropy = 0.811\\nsamples = 4\\nvalue = [1, 3]'),\n",
       " Text(261.743373031118, 129.76258064516128, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(263.801306185171, 129.76258064516128, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(262.7723396081445, 150.8051612903226, 'entropy = 0.0\\nsamples = 30\\nvalue = [30, 0]'),\n",
       " Text(267.917172493277, 157.81935483870967, 'X[11] <= 0.445\\nentropy = 0.991\\nsamples = 9\\nvalue = [5, 4]'),\n",
       " Text(266.8882059162505, 150.8051612903226, 'X[11] <= -0.288\\nentropy = 0.863\\nsamples = 7\\nvalue = [5, 2]'),\n",
       " Text(265.859239339224, 143.7909677419355, 'X[8] <= 0.761\\nentropy = 0.918\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(264.83027276219747, 136.7767741935484, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(266.8882059162505, 136.7767741935484, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(267.917172493277, 143.7909677419355, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(268.9461390703035, 150.8051612903226, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(273.5764886669228, 171.84774193548387, 'X[10] <= -1.398\\nentropy = 0.75\\nsamples = 126\\nvalue = [99, 27]'),\n",
       " Text(272.5475220898963, 164.83354838709678, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(274.60545524394934, 164.83354838709678, 'X[8] <= 1.167\\nentropy = 0.725\\nsamples = 124\\nvalue = [99, 25]'),\n",
       " Text(272.03303880138304, 157.81935483870967, 'X[9] <= 2.716\\nentropy = 0.852\\nsamples = 72\\nvalue = [52, 20]'),\n",
       " Text(271.00407222435655, 150.8051612903226, 'X[9] <= 1.537\\nentropy = 0.805\\nsamples = 69\\nvalue = [52, 17]'),\n",
       " Text(269.97510564733, 143.7909677419355, 'X[9] <= 0.964\\nentropy = 0.86\\nsamples = 60\\nvalue = [43, 17]'),\n",
       " Text(268.9461390703035, 136.7767741935484, 'X[8] <= 0.621\\nentropy = 0.729\\nsamples = 54\\nvalue = [43, 11]'),\n",
       " Text(267.917172493277, 129.76258064516128, 'entropy = 0.0\\nsamples = 12\\nvalue = [12, 0]'),\n",
       " Text(269.97510564733, 129.76258064516128, 'X[7] <= 0.335\\nentropy = 0.83\\nsamples = 42\\nvalue = [31, 11]'),\n",
       " Text(268.9461390703035, 122.7483870967742, 'entropy = 0.0\\nsamples = 6\\nvalue = [6, 0]'),\n",
       " Text(271.00407222435655, 122.7483870967742, 'X[2] <= -0.624\\nentropy = 0.888\\nsamples = 36\\nvalue = [25, 11]'),\n",
       " Text(269.97510564733, 115.7341935483871, 'X[1] <= 1.971\\nentropy = 0.758\\nsamples = 32\\nvalue = [25, 7]'),\n",
       " Text(268.9461390703035, 108.72, 'X[9] <= 0.7\\nentropy = 0.709\\nsamples = 31\\nvalue = [25, 6]'),\n",
       " Text(266.8882059162505, 101.70580645161291, 'X[8] <= 0.819\\nentropy = 0.592\\nsamples = 28\\nvalue = [24, 4]'),\n",
       " Text(265.859239339224, 94.69161290322582, 'entropy = 0.0\\nsamples = 11\\nvalue = [11, 0]'),\n",
       " Text(267.917172493277, 94.69161290322582, 'X[8] <= 0.993\\nentropy = 0.787\\nsamples = 17\\nvalue = [13, 4]'),\n",
       " Text(266.8882059162505, 87.67741935483872, 'X[9] <= -0.114\\nentropy = 0.991\\nsamples = 9\\nvalue = [5, 4]'),\n",
       " Text(264.83027276219747, 80.6632258064516, 'X[10] <= -0.648\\nentropy = 0.722\\nsamples = 5\\nvalue = [4, 1]'),\n",
       " Text(263.801306185171, 73.64903225806452, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(265.859239339224, 73.64903225806452, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(268.9461390703035, 80.6632258064516, 'X[0] <= 0.144\\nentropy = 0.811\\nsamples = 4\\nvalue = [1, 3]'),\n",
       " Text(267.917172493277, 73.64903225806452, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(269.97510564733, 73.64903225806452, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(268.9461390703035, 87.67741935483872, 'entropy = 0.0\\nsamples = 8\\nvalue = [8, 0]'),\n",
       " Text(271.00407222435655, 101.70580645161291, 'X[8] <= 0.691\\nentropy = 0.918\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(269.97510564733, 94.69161290322582, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(272.03303880138304, 94.69161290322582, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(271.00407222435655, 108.72, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(272.03303880138304, 115.7341935483871, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 4]'),\n",
       " Text(271.00407222435655, 136.7767741935484, 'entropy = 0.0\\nsamples = 6\\nvalue = [0, 6]'),\n",
       " Text(272.03303880138304, 143.7909677419355, 'entropy = 0.0\\nsamples = 9\\nvalue = [9, 0]'),\n",
       " Text(273.06200537840954, 150.8051612903226, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(277.1778716865156, 157.81935483870967, 'X[11] <= -1.091\\nentropy = 0.457\\nsamples = 52\\nvalue = [47, 5]'),\n",
       " Text(275.1199385324626, 150.8051612903226, 'X[3] <= 2.879\\nentropy = 0.918\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(274.09097195543603, 143.7909677419355, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(276.1489051094891, 143.7909677419355, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(279.2358048405686, 150.8051612903226, 'X[8] <= 1.596\\nentropy = 0.332\\nsamples = 49\\nvalue = [46, 3]'),\n",
       " Text(278.20683826354207, 143.7909677419355, 'entropy = 0.0\\nsamples = 30\\nvalue = [30, 0]'),\n",
       " Text(280.2647714175951, 143.7909677419355, 'X[8] <= 1.677\\nentropy = 0.629\\nsamples = 19\\nvalue = [16, 3]'),\n",
       " Text(279.2358048405686, 136.7767741935484, 'X[9] <= 0.696\\nentropy = 0.918\\nsamples = 9\\nvalue = [6, 3]'),\n",
       " Text(278.20683826354207, 129.76258064516128, 'X[9] <= 0.373\\nentropy = 1.0\\nsamples = 6\\nvalue = [3, 3]'),\n",
       " Text(277.1778716865156, 122.7483870967742, 'X[7] <= 0.288\\nentropy = 0.811\\nsamples = 4\\nvalue = [3, 1]'),\n",
       " Text(276.1489051094891, 115.7341935483871, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(278.20683826354207, 115.7341935483871, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(279.2358048405686, 122.7483870967742, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(280.2647714175951, 129.76258064516128, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(281.2937379946216, 136.7767741935484, 'entropy = 0.0\\nsamples = 10\\nvalue = [10, 0]'),\n",
       " Text(298.0144448713024, 185.87612903225806, 'X[11] <= 0.305\\nentropy = 0.952\\nsamples = 129\\nvalue = [81, 48]'),\n",
       " Text(291.32616212063004, 178.86193548387098, 'X[9] <= 0.988\\nentropy = 0.874\\nsamples = 85\\nvalue = [60, 25]'),\n",
       " Text(287.46753745678063, 171.84774193548387, 'X[9] <= 0.622\\nentropy = 0.736\\nsamples = 58\\nvalue = [46, 12]'),\n",
       " Text(286.43857087975414, 164.83354838709678, 'X[2] <= -0.708\\nentropy = 0.828\\nsamples = 46\\nvalue = [34, 12]'),\n",
       " Text(285.40960430272764, 157.81935483870967, 'X[7] <= -0.567\\nentropy = 0.918\\nsamples = 36\\nvalue = [24, 12]'),\n",
       " Text(283.35167114867465, 150.8051612903226, 'X[0] <= 0.144\\nentropy = 0.722\\nsamples = 5\\nvalue = [1, 4]'),\n",
       " Text(282.3227045716481, 143.7909677419355, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 4]'),\n",
       " Text(284.38063772570115, 143.7909677419355, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(287.46753745678063, 150.8051612903226, 'X[1] <= 1.388\\nentropy = 0.824\\nsamples = 31\\nvalue = [23, 8]'),\n",
       " Text(286.43857087975414, 143.7909677419355, 'X[10] <= 0.184\\nentropy = 0.959\\nsamples = 21\\nvalue = [13, 8]'),\n",
       " Text(284.38063772570115, 136.7767741935484, 'X[8] <= 1.921\\nentropy = 0.811\\nsamples = 16\\nvalue = [12, 4]'),\n",
       " Text(283.35167114867465, 129.76258064516128, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(285.40960430272764, 129.76258064516128, 'X[1] <= 0.922\\nentropy = 0.592\\nsamples = 14\\nvalue = [12, 2]'),\n",
       " Text(284.38063772570115, 122.7483870967742, 'X[3] <= 2.879\\nentropy = 0.863\\nsamples = 7\\nvalue = [5, 2]'),\n",
       " Text(283.35167114867465, 115.7341935483871, 'X[8] <= 2.849\\nentropy = 0.65\\nsamples = 6\\nvalue = [5, 1]'),\n",
       " Text(282.3227045716481, 108.72, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
       " Text(284.38063772570115, 108.72, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(285.40960430272764, 115.7341935483871, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(286.43857087975414, 122.7483870967742, 'entropy = 0.0\\nsamples = 7\\nvalue = [7, 0]'),\n",
       " Text(288.4965040338072, 136.7767741935484, 'X[10] <= 2.433\\nentropy = 0.722\\nsamples = 5\\nvalue = [1, 4]'),\n",
       " Text(287.46753745678063, 129.76258064516128, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 4]'),\n",
       " Text(289.5254706108337, 129.76258064516128, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(288.4965040338072, 143.7909677419355, 'entropy = 0.0\\nsamples = 10\\nvalue = [10, 0]'),\n",
       " Text(287.46753745678063, 157.81935483870967, 'entropy = 0.0\\nsamples = 10\\nvalue = [10, 0]'),\n",
       " Text(288.4965040338072, 164.83354838709678, 'entropy = 0.0\\nsamples = 12\\nvalue = [12, 0]'),\n",
       " Text(295.18478678447946, 171.84774193548387, 'X[10] <= 0.393\\nentropy = 0.999\\nsamples = 27\\nvalue = [14, 13]'),\n",
       " Text(292.6123703419132, 164.83354838709678, 'X[1] <= 0.281\\nentropy = 0.918\\nsamples = 18\\nvalue = [12, 6]'),\n",
       " Text(291.58340376488667, 157.81935483870967, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(293.6413369189397, 157.81935483870967, 'X[9] <= 1.14\\nentropy = 0.811\\nsamples = 16\\nvalue = [12, 4]'),\n",
       " Text(291.58340376488667, 150.8051612903226, 'X[9] <= 1.024\\nentropy = 0.918\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(290.5544371878602, 143.7909677419355, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(292.6123703419132, 143.7909677419355, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(295.6992700729927, 150.8051612903226, 'X[1] <= 1.097\\nentropy = 0.619\\nsamples = 13\\nvalue = [11, 2]'),\n",
       " Text(294.6703034959662, 143.7909677419355, 'X[9] <= 1.565\\nentropy = 1.0\\nsamples = 4\\nvalue = [2, 2]'),\n",
       " Text(293.6413369189397, 136.7767741935484, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(295.6992700729927, 136.7767741935484, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(296.72823665001926, 143.7909677419355, 'entropy = 0.0\\nsamples = 9\\nvalue = [9, 0]'),\n",
       " Text(297.75720322704575, 164.83354838709678, 'X[1] <= 0.339\\nentropy = 0.764\\nsamples = 9\\nvalue = [2, 7]'),\n",
       " Text(296.72823665001926, 157.81935483870967, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(298.78616980407224, 157.81935483870967, 'X[10] <= 1.85\\nentropy = 0.544\\nsamples = 8\\nvalue = [1, 7]'),\n",
       " Text(297.75720322704575, 150.8051612903226, 'entropy = 0.0\\nsamples = 7\\nvalue = [0, 7]'),\n",
       " Text(299.81513638109874, 150.8051612903226, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(304.70272762197465, 178.86193548387098, 'X[1] <= 0.922\\nentropy = 0.999\\nsamples = 44\\nvalue = [21, 23]'),\n",
       " Text(300.8441029581253, 171.84774193548387, 'X[7] <= 1.997\\nentropy = 0.503\\nsamples = 9\\nvalue = [1, 8]'),\n",
       " Text(299.81513638109874, 164.83354838709678, 'entropy = 0.0\\nsamples = 7\\nvalue = [0, 7]'),\n",
       " Text(301.8730695351518, 164.83354838709678, 'X[11] <= 1.597\\nentropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(300.8441029581253, 157.81935483870967, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(302.9020361121783, 157.81935483870967, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(308.56135228582406, 171.84774193548387, 'X[9] <= 0.058\\nentropy = 0.985\\nsamples = 35\\nvalue = [20, 15]'),\n",
       " Text(305.9889358432578, 164.83354838709678, 'X[9] <= -0.278\\nentropy = 0.845\\nsamples = 11\\nvalue = [3, 8]'),\n",
       " Text(304.95996926623127, 157.81935483870967, 'X[10] <= 0.767\\nentropy = 0.985\\nsamples = 7\\nvalue = [3, 4]'),\n",
       " Text(303.9310026892048, 150.8051612903226, 'X[7] <= 2.828\\nentropy = 0.811\\nsamples = 4\\nvalue = [3, 1]'),\n",
       " Text(302.9020361121783, 143.7909677419355, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(304.95996926623127, 143.7909677419355, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(305.9889358432578, 150.8051612903226, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(307.0179024202843, 157.81935483870967, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 4]'),\n",
       " Text(311.13376872839035, 164.83354838709678, 'X[10] <= 0.517\\nentropy = 0.871\\nsamples = 24\\nvalue = [17, 7]'),\n",
       " Text(309.0758355743373, 157.81935483870967, 'X[10] <= -0.898\\nentropy = 1.0\\nsamples = 12\\nvalue = [6, 6]'),\n",
       " Text(308.0468689973108, 150.8051612903226, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(310.10480215136386, 150.8051612903226, 'X[9] <= 0.507\\nentropy = 0.918\\nsamples = 9\\nvalue = [3, 6]'),\n",
       " Text(309.0758355743373, 143.7909677419355, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(311.13376872839035, 143.7909677419355, 'X[4] <= 6.593\\nentropy = 0.592\\nsamples = 7\\nvalue = [1, 6]'),\n",
       " Text(310.10480215136386, 136.7767741935484, 'entropy = 0.0\\nsamples = 6\\nvalue = [0, 6]'),\n",
       " Text(312.16273530541685, 136.7767741935484, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(313.19170188244334, 157.81935483870967, 'X[10] <= 3.057\\nentropy = 0.414\\nsamples = 12\\nvalue = [11, 1]'),\n",
       " Text(312.16273530541685, 150.8051612903226, 'entropy = 0.0\\nsamples = 11\\nvalue = [11, 0]'),\n",
       " Text(314.2206684594699, 150.8051612903226, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(325.0248175182482, 192.89032258064515, 'X[11] <= -0.323\\nentropy = 0.997\\nsamples = 139\\nvalue = [74, 65]'),\n",
       " Text(321.93791778716866, 185.87612903225806, 'X[7] <= 1.576\\nentropy = 0.843\\nsamples = 59\\nvalue = [43, 16]'),\n",
       " Text(320.90895121014216, 178.86193548387098, 'X[7] <= -1.468\\nentropy = 0.897\\nsamples = 51\\nvalue = [35, 16]'),\n",
       " Text(319.87998463311567, 171.84774193548387, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(321.93791778716866, 171.84774193548387, 'X[7] <= 1.201\\nentropy = 0.863\\nsamples = 49\\nvalue = [35, 14]'),\n",
       " Text(320.90895121014216, 164.83354838709678, 'X[2] <= 1.138\\nentropy = 0.82\\nsamples = 47\\nvalue = [35, 12]'),\n",
       " Text(319.87998463311567, 157.81935483870967, 'X[1] <= 1.213\\nentropy = 0.909\\nsamples = 37\\nvalue = [25, 12]'),\n",
       " Text(317.3075681905494, 150.8051612903226, 'X[7] <= 0.581\\nentropy = 0.764\\nsamples = 27\\nvalue = [21, 6]'),\n",
       " Text(316.2786016135229, 143.7909677419355, 'X[7] <= 0.007\\nentropy = 0.9\\nsamples = 19\\nvalue = [13, 6]'),\n",
       " Text(314.2206684594699, 136.7767741935484, 'X[8] <= 1.329\\nentropy = 0.619\\nsamples = 13\\nvalue = [11, 2]'),\n",
       " Text(313.19170188244334, 129.76258064516128, 'entropy = 0.0\\nsamples = 9\\nvalue = [9, 0]'),\n",
       " Text(315.2496350364964, 129.76258064516128, 'X[10] <= 0.018\\nentropy = 1.0\\nsamples = 4\\nvalue = [2, 2]'),\n",
       " Text(314.2206684594699, 122.7483870967742, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(316.2786016135229, 122.7483870967742, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(318.3365347675759, 136.7767741935484, 'X[10] <= 1.683\\nentropy = 0.918\\nsamples = 6\\nvalue = [2, 4]'),\n",
       " Text(317.3075681905494, 129.76258064516128, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 4]'),\n",
       " Text(319.3655013446024, 129.76258064516128, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(318.3365347675759, 143.7909677419355, 'entropy = 0.0\\nsamples = 8\\nvalue = [8, 0]'),\n",
       " Text(322.4524010756819, 150.8051612903226, 'X[10] <= 0.559\\nentropy = 0.971\\nsamples = 10\\nvalue = [4, 6]'),\n",
       " Text(321.4234344986554, 143.7909677419355, 'X[7] <= 0.967\\nentropy = 0.592\\nsamples = 7\\nvalue = [1, 6]'),\n",
       " Text(320.3944679216289, 136.7767741935484, 'entropy = 0.0\\nsamples = 6\\nvalue = [0, 6]'),\n",
       " Text(322.4524010756819, 136.7767741935484, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(323.48136765270846, 143.7909677419355, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(321.93791778716866, 157.81935483870967, 'entropy = 0.0\\nsamples = 10\\nvalue = [10, 0]'),\n",
       " Text(322.9668843641952, 164.83354838709678, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(322.9668843641952, 178.86193548387098, 'entropy = 0.0\\nsamples = 8\\nvalue = [8, 0]'),\n",
       " Text(328.11171724932774, 185.87612903225806, 'X[1] <= 0.222\\nentropy = 0.963\\nsamples = 80\\nvalue = [31, 49]'),\n",
       " Text(325.53930080676145, 178.86193548387098, 'X[10] <= 1.1\\nentropy = 0.696\\nsamples = 16\\nvalue = [13, 3]'),\n",
       " Text(324.51033422973495, 171.84774193548387, 'entropy = 0.0\\nsamples = 13\\nvalue = [13, 0]'),\n",
       " Text(326.56826738378794, 171.84774193548387, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(330.684133691894, 178.86193548387098, 'X[7] <= 0.37\\nentropy = 0.857\\nsamples = 64\\nvalue = [18, 46]'),\n",
       " Text(328.626200537841, 171.84774193548387, 'X[1] <= 1.738\\nentropy = 0.971\\nsamples = 40\\nvalue = [16, 24]'),\n",
       " Text(327.5972339608145, 164.83354838709678, 'X[10] <= -0.773\\nentropy = 0.998\\nsamples = 34\\nvalue = [16, 18]'),\n",
       " Text(326.56826738378794, 157.81935483870967, 'entropy = 0.0\\nsamples = 5\\nvalue = [0, 5]'),\n",
       " Text(328.626200537841, 157.81935483870967, 'X[2] <= 2.187\\nentropy = 0.992\\nsamples = 29\\nvalue = [16, 13]'),\n",
       " Text(327.5972339608145, 150.8051612903226, 'X[8] <= 2.315\\nentropy = 0.918\\nsamples = 24\\nvalue = [16, 8]'),\n",
       " Text(325.53930080676145, 143.7909677419355, 'X[10] <= 0.434\\nentropy = 0.742\\nsamples = 19\\nvalue = [15, 4]'),\n",
       " Text(324.51033422973495, 136.7767741935484, 'X[9] <= 0.755\\nentropy = 0.971\\nsamples = 10\\nvalue = [6, 4]'),\n",
       " Text(323.48136765270846, 129.76258064516128, 'X[11] <= 1.632\\nentropy = 0.592\\nsamples = 7\\nvalue = [6, 1]'),\n",
       " Text(322.4524010756819, 122.7483870967742, 'entropy = 0.0\\nsamples = 6\\nvalue = [6, 0]'),\n",
       " Text(324.51033422973495, 122.7483870967742, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(325.53930080676145, 129.76258064516128, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(326.56826738378794, 136.7767741935484, 'entropy = 0.0\\nsamples = 9\\nvalue = [9, 0]'),\n",
       " Text(329.6551671148675, 143.7909677419355, 'X[2] <= 0.719\\nentropy = 0.722\\nsamples = 5\\nvalue = [1, 4]'),\n",
       " Text(328.626200537841, 136.7767741935484, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(330.684133691894, 136.7767741935484, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 4]'),\n",
       " Text(329.6551671148675, 150.8051612903226, 'entropy = 0.0\\nsamples = 5\\nvalue = [0, 5]'),\n",
       " Text(329.6551671148675, 164.83354838709678, 'entropy = 0.0\\nsamples = 6\\nvalue = [0, 6]'),\n",
       " Text(332.742066845947, 171.84774193548387, 'X[9] <= -0.149\\nentropy = 0.414\\nsamples = 24\\nvalue = [2, 22]'),\n",
       " Text(331.7131002689205, 164.83354838709678, 'X[9] <= -0.315\\nentropy = 0.722\\nsamples = 10\\nvalue = [2, 8]'),\n",
       " ...]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#display the decission tree\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "tree.plot_tree(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- feature_1 <= -0.13\n",
      "|   |--- feature_2 <= 0.05\n",
      "|   |   |--- feature_8 <= -0.16\n",
      "|   |   |   |--- feature_9 <= -0.18\n",
      "|   |   |   |   |--- feature_11 <= -0.18\n",
      "|   |   |   |   |   |--- feature_10 <= 0.73\n",
      "|   |   |   |   |   |   |--- feature_7 <= -1.54\n",
      "|   |   |   |   |   |   |   |--- feature_11 <= -1.02\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_11 >  -1.02\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_7 >  -1.54\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_10 >  0.73\n",
      "|   |   |   |   |   |   |--- feature_1 <= -1.18\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_1 >  -1.18\n",
      "|   |   |   |   |   |   |   |--- feature_9 <= -0.38\n",
      "|   |   |   |   |   |   |   |   |--- feature_9 <= -0.64\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_11 <= -0.25\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_11 >  -0.25\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_9 <= -0.97\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_9 >  -0.97\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_9 >  -0.64\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_9 >  -0.38\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- feature_11 >  -0.18\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- feature_9 >  -0.18\n",
      "|   |   |   |   |--- feature_9 <= -0.17\n",
      "|   |   |   |   |   |--- feature_2 <= -0.71\n",
      "|   |   |   |   |   |   |--- feature_1 <= -1.06\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_1 >  -1.06\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_2 >  -0.71\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- feature_9 >  -0.17\n",
      "|   |   |   |   |   |--- feature_10 <= 0.14\n",
      "|   |   |   |   |   |   |--- feature_11 <= 2.47\n",
      "|   |   |   |   |   |   |   |--- feature_10 <= 0.06\n",
      "|   |   |   |   |   |   |   |   |--- feature_7 <= -0.73\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_7 <= -0.99\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_9 <= 1.20\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_9 >  1.20\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_7 >  -0.99\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_10 <= -0.94\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_10 >  -0.94\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |--- feature_7 >  -0.73\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_11 <= -1.41\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_11 <= -1.51\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_11 >  -1.51\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_11 >  -1.41\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_10 >  0.06\n",
      "|   |   |   |   |   |   |   |   |--- feature_7 <= -0.00\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_7 >  -0.00\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_11 >  2.47\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_10 >  0.14\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |--- feature_8 >  -0.16\n",
      "|   |   |   |--- feature_7 <= -0.66\n",
      "|   |   |   |   |--- feature_1 <= -0.24\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- feature_1 >  -0.24\n",
      "|   |   |   |   |   |--- feature_0 <= 0.14\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_0 >  0.14\n",
      "|   |   |   |   |   |   |--- feature_9 <= 0.53\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_9 >  0.53\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- feature_7 >  -0.66\n",
      "|   |   |   |   |--- feature_3 <= 2.88\n",
      "|   |   |   |   |   |--- feature_11 <= -0.74\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_11 >  -0.74\n",
      "|   |   |   |   |   |   |--- feature_10 <= -1.19\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_10 >  -1.19\n",
      "|   |   |   |   |   |   |   |--- feature_10 <= 0.73\n",
      "|   |   |   |   |   |   |   |   |--- feature_8 <= -0.13\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_11 <= -0.22\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_11 >  -0.22\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_8 >  -0.13\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_7 <= 2.63\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_7 <= -0.59\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_7 >  -0.59\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 11\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_7 >  2.63\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_10 >  0.73\n",
      "|   |   |   |   |   |   |   |   |--- feature_0 <= 0.14\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_0 >  0.14\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_9 <= 1.82\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_8 <= 0.74\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_8 >  0.74\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_9 >  1.82\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- feature_3 >  2.88\n",
      "|   |   |   |   |   |--- feature_1 <= -0.59\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_1 >  -0.59\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |--- feature_2 >  0.05\n",
      "|   |   |--- feature_8 <= 0.03\n",
      "|   |   |   |--- feature_7 <= -0.12\n",
      "|   |   |   |   |--- feature_1 <= -0.36\n",
      "|   |   |   |   |   |--- feature_9 <= 0.09\n",
      "|   |   |   |   |   |   |--- feature_9 <= 0.08\n",
      "|   |   |   |   |   |   |   |--- feature_10 <= 0.81\n",
      "|   |   |   |   |   |   |   |   |--- feature_8 <= -1.33\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_8 >  -1.33\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_8 <= -0.26\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_8 <= -0.35\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 13\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_8 >  -0.35\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_8 >  -0.26\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_10 >  0.81\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_9 >  0.08\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_9 >  0.09\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- feature_1 >  -0.36\n",
      "|   |   |   |   |   |--- feature_7 <= -1.54\n",
      "|   |   |   |   |   |   |--- feature_0 <= 0.14\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_0 >  0.14\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_7 >  -1.54\n",
      "|   |   |   |   |   |   |--- feature_7 <= -0.67\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_7 >  -0.67\n",
      "|   |   |   |   |   |   |   |--- feature_7 <= -0.59\n",
      "|   |   |   |   |   |   |   |   |--- feature_8 <= -0.07\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_8 >  -0.07\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_7 >  -0.59\n",
      "|   |   |   |   |   |   |   |   |--- feature_9 <= -1.43\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_9 >  -1.43\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- feature_7 >  -0.12\n",
      "|   |   |   |   |--- feature_6 <= 3.61\n",
      "|   |   |   |   |   |--- feature_9 <= -1.23\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_9 >  -1.23\n",
      "|   |   |   |   |   |   |--- feature_11 <= -0.95\n",
      "|   |   |   |   |   |   |   |--- feature_10 <= -0.77\n",
      "|   |   |   |   |   |   |   |   |--- feature_1 <= -1.06\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_1 >  -1.06\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_10 >  -0.77\n",
      "|   |   |   |   |   |   |   |   |--- feature_9 <= 1.42\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_7 <= 0.43\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_8 <= -0.47\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_8 >  -0.47\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_7 >  0.43\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_9 >  1.42\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_11 >  -0.95\n",
      "|   |   |   |   |   |   |   |--- feature_8 <= -0.23\n",
      "|   |   |   |   |   |   |   |   |--- feature_10 <= -0.69\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_9 <= -1.08\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_7 <= 1.21\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_7 >  1.21\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_9 >  -1.08\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_10 >  -0.69\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_5 <= 0.41\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_9 <= -1.20\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_9 >  -1.20\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 20\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_5 >  0.41\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_1 <= -0.77\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_1 >  -0.77\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_8 >  -0.23\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- feature_6 >  3.61\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |--- feature_8 >  0.03\n",
      "|   |   |   |--- feature_9 <= -0.97\n",
      "|   |   |   |   |--- feature_7 <= 0.65\n",
      "|   |   |   |   |   |--- feature_9 <= -1.54\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_9 >  -1.54\n",
      "|   |   |   |   |   |   |--- feature_8 <= 0.77\n",
      "|   |   |   |   |   |   |   |--- feature_1 <= -0.89\n",
      "|   |   |   |   |   |   |   |   |--- feature_2 <= 0.72\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_2 >  0.72\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_1 <= -1.41\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_1 >  -1.41\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_1 >  -0.89\n",
      "|   |   |   |   |   |   |   |   |--- feature_10 <= -0.27\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_10 >  -0.27\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_11 <= -0.11\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_11 >  -0.11\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_8 >  0.77\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- feature_7 >  0.65\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- feature_9 >  -0.97\n",
      "|   |   |   |   |--- feature_7 <= 3.45\n",
      "|   |   |   |   |   |--- feature_2 <= 0.80\n",
      "|   |   |   |   |   |   |--- feature_9 <= 0.38\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_9 >  0.38\n",
      "|   |   |   |   |   |   |   |--- feature_9 <= 0.44\n",
      "|   |   |   |   |   |   |   |   |--- feature_7 <= -0.23\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_7 >  -0.23\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_9 >  0.44\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_2 >  0.80\n",
      "|   |   |   |   |   |   |--- feature_8 <= 0.08\n",
      "|   |   |   |   |   |   |   |--- feature_9 <= 0.23\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_9 >  0.23\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_8 >  0.08\n",
      "|   |   |   |   |   |   |   |--- feature_8 <= 0.24\n",
      "|   |   |   |   |   |   |   |   |--- feature_9 <= -0.47\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_9 <= -0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_9 >  -0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_9 >  -0.47\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_8 >  0.24\n",
      "|   |   |   |   |   |   |   |   |--- feature_1 <= -1.29\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_1 >  -1.29\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_7 <= 0.48\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_11 <= 0.58\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 7\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_11 >  0.58\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_7 >  0.48\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_9 <= -0.10\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_9 >  -0.10\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 4\n",
      "|   |   |   |   |--- feature_7 >  3.45\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|--- feature_1 >  -0.13\n",
      "|   |--- feature_8 <= 0.49\n",
      "|   |   |--- feature_1 <= 1.85\n",
      "|   |   |   |--- feature_8 <= -1.08\n",
      "|   |   |   |   |--- feature_2 <= 2.52\n",
      "|   |   |   |   |   |--- feature_7 <= -1.99\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_7 >  -1.99\n",
      "|   |   |   |   |   |   |--- feature_11 <= 5.68\n",
      "|   |   |   |   |   |   |   |--- feature_8 <= -1.32\n",
      "|   |   |   |   |   |   |   |   |--- feature_8 <= -1.36\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_7 <= 1.53\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_7 >  1.53\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_8 <= -1.64\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_8 >  -1.64\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_8 >  -1.36\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_10 <= 0.35\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_7 <= -0.98\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_7 >  -0.98\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_10 >  0.35\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_8 >  -1.32\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_11 >  5.68\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- feature_2 >  2.52\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |--- feature_8 >  -1.08\n",
      "|   |   |   |   |--- feature_0 <= 0.14\n",
      "|   |   |   |   |   |--- feature_10 <= 1.10\n",
      "|   |   |   |   |   |   |--- feature_9 <= 1.89\n",
      "|   |   |   |   |   |   |   |--- feature_10 <= 0.73\n",
      "|   |   |   |   |   |   |   |   |--- feature_9 <= 1.14\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_3 <= 2.88\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_10 <= 0.64\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 14\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_10 >  0.64\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_3 >  2.88\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_10 <= -0.69\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_10 >  -0.69\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_9 >  1.14\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_10 >  0.73\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_9 >  1.89\n",
      "|   |   |   |   |   |   |   |--- feature_7 <= -0.13\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_7 >  -0.13\n",
      "|   |   |   |   |   |   |   |   |--- feature_8 <= 0.26\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_8 <= -0.07\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_8 >  -0.07\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_8 >  0.26\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_10 >  1.10\n",
      "|   |   |   |   |   |   |--- feature_2 <= 0.30\n",
      "|   |   |   |   |   |   |   |--- feature_9 <= -0.13\n",
      "|   |   |   |   |   |   |   |   |--- feature_7 <= -0.96\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_8 <= 0.02\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_8 >  0.02\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_7 >  -0.96\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_9 >  -0.13\n",
      "|   |   |   |   |   |   |   |   |--- feature_9 <= 0.85\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_7 <= 1.34\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_7 <= -0.51\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_7 >  -0.51\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 5\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_7 >  1.34\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_9 >  0.85\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_2 >  0.30\n",
      "|   |   |   |   |   |   |   |--- feature_9 <= -0.63\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_9 >  -0.63\n",
      "|   |   |   |   |   |   |   |   |--- feature_8 <= 0.30\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_8 >  0.30\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- feature_0 >  0.14\n",
      "|   |   |   |   |   |--- feature_11 <= -1.16\n",
      "|   |   |   |   |   |   |--- feature_1 <= 1.27\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_1 >  1.27\n",
      "|   |   |   |   |   |   |   |--- feature_1 <= 1.39\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_1 >  1.39\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_11 >  -1.16\n",
      "|   |   |   |   |   |   |--- feature_7 <= 2.35\n",
      "|   |   |   |   |   |   |   |--- feature_10 <= -0.27\n",
      "|   |   |   |   |   |   |   |   |--- feature_1 <= 0.11\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_1 >  0.11\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_11 <= 0.51\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_10 <= -1.40\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 6\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_10 >  -1.40\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 9\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_11 >  0.51\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_2 <= 2.19\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_2 >  2.19\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_10 >  -0.27\n",
      "|   |   |   |   |   |   |   |   |--- feature_11 <= -0.95\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_9 <= 0.13\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_7 <= -0.51\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_7 >  -0.51\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_9 >  0.13\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_11 >  -0.95\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_1 <= 0.46\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_9 <= 0.55\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 12\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_9 >  0.55\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 5\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_1 >  0.46\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_9 <= -0.49\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 7\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_9 >  -0.49\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 13\n",
      "|   |   |   |   |   |   |--- feature_7 >  2.35\n",
      "|   |   |   |   |   |   |   |--- feature_10 <= -0.07\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_10 >  -0.07\n",
      "|   |   |   |   |   |   |   |   |--- feature_7 <= 2.41\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_7 >  2.41\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |--- feature_1 >  1.85\n",
      "|   |   |   |--- feature_10 <= -1.19\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |   |   |--- feature_10 >  -1.19\n",
      "|   |   |   |   |--- feature_2 <= 0.05\n",
      "|   |   |   |   |   |--- feature_11 <= -1.16\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_11 >  -1.16\n",
      "|   |   |   |   |   |   |--- feature_10 <= -0.40\n",
      "|   |   |   |   |   |   |   |--- feature_7 <= 0.12\n",
      "|   |   |   |   |   |   |   |   |--- feature_9 <= -0.77\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_9 >  -0.77\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_9 <= 1.08\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_9 >  1.08\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_7 >  0.12\n",
      "|   |   |   |   |   |   |   |   |--- feature_11 <= 1.32\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_11 >  1.32\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_10 >  -0.40\n",
      "|   |   |   |   |   |   |   |--- feature_5 <= 0.41\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_5 >  0.41\n",
      "|   |   |   |   |   |   |   |   |--- feature_1 <= 2.09\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_1 >  2.09\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- feature_2 >  0.05\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |--- feature_8 >  0.49\n",
      "|   |   |--- feature_2 <= 0.30\n",
      "|   |   |   |--- feature_8 <= 1.84\n",
      "|   |   |   |   |--- feature_7 <= 0.11\n",
      "|   |   |   |   |   |--- feature_4 <= 6.59\n",
      "|   |   |   |   |   |   |--- feature_10 <= -1.52\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_10 >  -1.52\n",
      "|   |   |   |   |   |   |   |--- feature_1 <= 1.16\n",
      "|   |   |   |   |   |   |   |   |--- feature_10 <= -1.23\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_8 <= 1.09\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_9 <= 2.02\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_9 >  2.02\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_8 >  1.09\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_10 >  -1.23\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_9 <= 1.99\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_7 <= -0.13\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 7\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_7 >  -0.13\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 10\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_9 >  1.99\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_1 >  1.16\n",
      "|   |   |   |   |   |   |   |   |--- feature_7 <= -1.21\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_9 <= 2.43\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_8 <= 1.72\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_8 >  1.72\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_9 >  2.43\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_7 >  -1.21\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_7 <= -0.89\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_7 >  -0.89\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_1 <= 2.09\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 11\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_1 >  2.09\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_4 >  6.59\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- feature_7 >  0.11\n",
      "|   |   |   |   |   |--- feature_1 <= 0.81\n",
      "|   |   |   |   |   |   |--- feature_7 <= 0.70\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_7 >  0.70\n",
      "|   |   |   |   |   |   |   |--- feature_0 <= 0.14\n",
      "|   |   |   |   |   |   |   |   |--- feature_11 <= -0.32\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_11 <= -0.60\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_11 >  -0.60\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_1 <= 0.34\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_1 >  0.34\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |--- feature_11 >  -0.32\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_0 >  0.14\n",
      "|   |   |   |   |   |   |   |   |--- feature_11 <= 0.44\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_11 <= -0.29\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_8 <= 0.76\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_8 >  0.76\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_11 >  -0.29\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_11 >  0.44\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_1 >  0.81\n",
      "|   |   |   |   |   |   |--- feature_10 <= -1.40\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_10 >  -1.40\n",
      "|   |   |   |   |   |   |   |--- feature_8 <= 1.17\n",
      "|   |   |   |   |   |   |   |   |--- feature_9 <= 2.72\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_9 <= 1.54\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_9 <= 0.96\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 10\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_9 >  0.96\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_9 >  1.54\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_9 >  2.72\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_8 >  1.17\n",
      "|   |   |   |   |   |   |   |   |--- feature_11 <= -1.09\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_3 <= 2.88\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_3 >  2.88\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_11 >  -1.09\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_8 <= 1.60\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_8 >  1.60\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_8 <= 1.68\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 4\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_8 >  1.68\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- feature_8 >  1.84\n",
      "|   |   |   |   |--- feature_11 <= 0.31\n",
      "|   |   |   |   |   |--- feature_9 <= 0.99\n",
      "|   |   |   |   |   |   |--- feature_9 <= 0.62\n",
      "|   |   |   |   |   |   |   |--- feature_2 <= -0.71\n",
      "|   |   |   |   |   |   |   |   |--- feature_7 <= -0.57\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_0 <= 0.14\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_0 >  0.14\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_7 >  -0.57\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_1 <= 1.39\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_10 <= 0.18\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 5\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_10 >  0.18\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_1 >  1.39\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_2 >  -0.71\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_9 >  0.62\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_9 >  0.99\n",
      "|   |   |   |   |   |   |--- feature_10 <= 0.39\n",
      "|   |   |   |   |   |   |   |--- feature_1 <= 0.28\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_1 >  0.28\n",
      "|   |   |   |   |   |   |   |   |--- feature_9 <= 1.14\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_9 <= 1.02\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_9 >  1.02\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_9 >  1.14\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_1 <= 1.10\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_9 <= 1.57\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_9 >  1.57\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_1 >  1.10\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_10 >  0.39\n",
      "|   |   |   |   |   |   |   |--- feature_1 <= 0.34\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_1 >  0.34\n",
      "|   |   |   |   |   |   |   |   |--- feature_10 <= 1.85\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_10 >  1.85\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- feature_11 >  0.31\n",
      "|   |   |   |   |   |--- feature_1 <= 0.92\n",
      "|   |   |   |   |   |   |--- feature_7 <= 2.00\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_7 >  2.00\n",
      "|   |   |   |   |   |   |   |--- feature_11 <= 1.60\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_11 >  1.60\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_1 >  0.92\n",
      "|   |   |   |   |   |   |--- feature_9 <= 0.06\n",
      "|   |   |   |   |   |   |   |--- feature_9 <= -0.28\n",
      "|   |   |   |   |   |   |   |   |--- feature_10 <= 0.77\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_7 <= 2.83\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_7 >  2.83\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_10 >  0.77\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_9 >  -0.28\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_9 >  0.06\n",
      "|   |   |   |   |   |   |   |--- feature_10 <= 0.52\n",
      "|   |   |   |   |   |   |   |   |--- feature_10 <= -0.90\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_10 >  -0.90\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_9 <= 0.51\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_9 >  0.51\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_4 <= 6.59\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_4 >  6.59\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_10 >  0.52\n",
      "|   |   |   |   |   |   |   |   |--- feature_10 <= 3.06\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_10 >  3.06\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |--- feature_2 >  0.30\n",
      "|   |   |   |--- feature_11 <= -0.32\n",
      "|   |   |   |   |--- feature_7 <= 1.58\n",
      "|   |   |   |   |   |--- feature_7 <= -1.47\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_7 >  -1.47\n",
      "|   |   |   |   |   |   |--- feature_7 <= 1.20\n",
      "|   |   |   |   |   |   |   |--- feature_2 <= 1.14\n",
      "|   |   |   |   |   |   |   |   |--- feature_1 <= 1.21\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_7 <= 0.58\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_7 <= 0.01\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_7 >  0.01\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_7 >  0.58\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_1 >  1.21\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_10 <= 0.56\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_7 <= 0.97\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_7 >  0.97\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_10 >  0.56\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_2 >  1.14\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_7 >  1.20\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- feature_7 >  1.58\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- feature_11 >  -0.32\n",
      "|   |   |   |   |--- feature_1 <= 0.22\n",
      "|   |   |   |   |   |--- feature_10 <= 1.10\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_10 >  1.10\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- feature_1 >  0.22\n",
      "|   |   |   |   |   |--- feature_7 <= 0.37\n",
      "|   |   |   |   |   |   |--- feature_1 <= 1.74\n",
      "|   |   |   |   |   |   |   |--- feature_10 <= -0.77\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_10 >  -0.77\n",
      "|   |   |   |   |   |   |   |   |--- feature_2 <= 2.19\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_8 <= 2.32\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_10 <= 0.43\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_10 >  0.43\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_8 >  2.32\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_2 <= 0.72\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_2 >  0.72\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_2 >  2.19\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_1 >  1.74\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_7 >  0.37\n",
      "|   |   |   |   |   |   |--- feature_9 <= -0.15\n",
      "|   |   |   |   |   |   |   |--- feature_9 <= -0.32\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_9 >  -0.32\n",
      "|   |   |   |   |   |   |   |   |--- feature_8 <= 2.59\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_8 >  2.59\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_9 >  -0.15\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#display the  text representation\n",
    "text_representation=tree.export_text(model)\n",
    "print(text_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DecisionTreeClassifier',\n",
       " 'DecisionTreeRegressor',\n",
       " 'ExtraTreeClassifier',\n",
       " 'ExtraTreeRegressor',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_criterion',\n",
       " '_reingold_tilford',\n",
       " '_splitter',\n",
       " '_tree',\n",
       " '_utils',\n",
       " 'export',\n",
       " 'export_graphviz',\n",
       " 'export_text',\n",
       " 'plot_tree',\n",
       " 'tree']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred=model.predict(X_test)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of decisiion tree moddel is: 74.91\n"
     ]
    }
   ],
   "source": [
    "#find accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc_D=accuracy_score(Y_pred,Y_test)\n",
    "acc_D=round(acc_D*100,2)\n",
    "print(\"accuracy of decisiion tree moddel is:\",acc_D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# support vector machine model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "sv=SVC()\n",
    "#train the model\n",
    "sv.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test the model\n",
    "Y_pred=sv.predict(X_test)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of svc moddel is: 85.02\n"
     ]
    }
   ],
   "source": [
    "#find accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc_DT=accuracy_score(Y_pred,Y_test)\n",
    "acc_DT=round(acc_DT*100,2)\n",
    "print(\"accuracy of svc moddel is:\",acc_DT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RFC=RandomForestClassifier()\n",
    "RFC.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test the model\n",
    "Y_pred=RFC.predict(X_test)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of random forest is: 84.19\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "acc_RFC=accuracy_score(Y_pred,Y_test)\n",
    "acc_RFC=round(acc_RFC*100,2)\n",
    "print(\"accuracy of random forest is:\",acc_RFC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# comparision accuracy of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression model accuracy is 84.66\n",
    "#kNN nearest neighbirs model accuracy is 84.90\n",
    "#NB naive bayes model accuracy is 83.12\n",
    "#decission tree model accuracy is 75.51\n",
    "#support vector machine(svm) model accuracy is 85.02\n",
    "#random forest model accuracy is 84.30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so the best model for heart dieases prediction is support vector machine(svm)\n",
    "#accuracy is 85.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
